{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fq80nlrAs-AM",
        "outputId": "08693156-f6f5-41be-c3d7-a7a2d3f6a762"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras_tuner in /usr/local/lib/python3.10/dist-packages (1.4.7)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (2.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (24.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (2.31.0)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (1.0.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (2024.6.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install keras_tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "8TYWdcNQgGA_"
      },
      "outputs": [],
      "source": [
        "# Dependencies\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# File paths and Tensorflow\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "# Sklearn scaling\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Random forest model imports\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "\n",
        "# from tensorflow.keras\n",
        "import sklearn as skl\n",
        "\n",
        "# from tensorflow import keras\n",
        "import keras_tuner as kt\n",
        "from sklearn.datasets import make_circles\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "7XJRhDEzjm0j",
        "outputId": "5598b97a-b506-4bed-f8cd-671faa87cdbf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0  N_Days Status             Drug    Age Sex Ascites  \\\n",
              "0              0    2221      C          Placebo  18499   F       N   \n",
              "1              1    1230      C          Placebo  19724   M       Y   \n",
              "2              2    4184      C          Placebo  11839   F       N   \n",
              "3              3    2090      D          Placebo  16467   F       N   \n",
              "4              4    2105      D          Placebo  21699   F       N   \n",
              "...          ...     ...    ...              ...    ...  ..     ...   \n",
              "9634       24963    3577      C          Placebo  17897   F       Y   \n",
              "9635       24971    4795      C          Placebo  23376   F       Y   \n",
              "9636       24972    3358      D  D-penicillamine  24585   F       N   \n",
              "9637       24991    4365      C  D-penicillamine  21324   F       N   \n",
              "9638       24992     694      D  D-penicillamine  28650   M       Y   \n",
              "\n",
              "     Hepatomegaly Spiders Edema  Bilirubin  Cholesterol  Albumin      Copper  \\\n",
              "0               Y       N     N        0.5   149.000000     4.04  227.000000   \n",
              "1               N       Y     N        0.5   219.000000     3.93   22.000000   \n",
              "2               N       N     N        0.5   320.000000     3.54   51.000000   \n",
              "3               N       N     N        0.7   255.000000     3.74   23.000000   \n",
              "4               Y       N     N        1.9   486.000000     3.54   74.000000   \n",
              "...           ...     ...   ...        ...          ...      ...         ...   \n",
              "9634            N       Y     N        0.7   369.510563     3.49   97.648387   \n",
              "9635            N       Y     N        1.8   369.510563     3.24   97.648387   \n",
              "9636            Y       N     N        2.1   262.000000     3.48   58.000000   \n",
              "9637            N       N     N        0.9   346.000000     3.40   81.000000   \n",
              "9638            Y       Y     N        0.8   300.000000     2.94  231.000000   \n",
              "\n",
              "         Alk_Phos        SGOT  Tryglicerides  Platelets  Prothrombin  Stage  \n",
              "0      598.000000   52.700000      57.000000      256.0          9.9      1  \n",
              "1      663.000000   45.000000      75.000000      220.0         10.8      2  \n",
              "2     1243.000000  122.450000      80.000000      225.0         10.0      2  \n",
              "3     1024.000000   77.500000      58.000000      151.0         10.2      2  \n",
              "4     1052.000000  108.500000     109.000000      151.0         11.5      1  \n",
              "...           ...         ...            ...        ...          ...    ...  \n",
              "9634  1982.655769  122.556346     124.702128      243.0          9.7      1  \n",
              "9635  1982.655769  122.556346     124.702128      139.0         10.5      1  \n",
              "9636  2045.000000   89.900000      84.000000      412.0         11.8      3  \n",
              "9637  1098.000000  122.450000      90.000000      228.0         10.3      2  \n",
              "9638  1794.000000  130.200000      99.000000       97.0         11.2      3  \n",
              "\n",
              "[9639 rows x 20 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0d1889c9-cad3-4380-a221-13dfb19949bb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>N_Days</th>\n",
              "      <th>Status</th>\n",
              "      <th>Drug</th>\n",
              "      <th>Age</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Ascites</th>\n",
              "      <th>Hepatomegaly</th>\n",
              "      <th>Spiders</th>\n",
              "      <th>Edema</th>\n",
              "      <th>Bilirubin</th>\n",
              "      <th>Cholesterol</th>\n",
              "      <th>Albumin</th>\n",
              "      <th>Copper</th>\n",
              "      <th>Alk_Phos</th>\n",
              "      <th>SGOT</th>\n",
              "      <th>Tryglicerides</th>\n",
              "      <th>Platelets</th>\n",
              "      <th>Prothrombin</th>\n",
              "      <th>Stage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2221</td>\n",
              "      <td>C</td>\n",
              "      <td>Placebo</td>\n",
              "      <td>18499</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>0.5</td>\n",
              "      <td>149.000000</td>\n",
              "      <td>4.04</td>\n",
              "      <td>227.000000</td>\n",
              "      <td>598.000000</td>\n",
              "      <td>52.700000</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>256.0</td>\n",
              "      <td>9.9</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1230</td>\n",
              "      <td>C</td>\n",
              "      <td>Placebo</td>\n",
              "      <td>19724</td>\n",
              "      <td>M</td>\n",
              "      <td>Y</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>N</td>\n",
              "      <td>0.5</td>\n",
              "      <td>219.000000</td>\n",
              "      <td>3.93</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>663.000000</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>220.0</td>\n",
              "      <td>10.8</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>4184</td>\n",
              "      <td>C</td>\n",
              "      <td>Placebo</td>\n",
              "      <td>11839</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>0.5</td>\n",
              "      <td>320.000000</td>\n",
              "      <td>3.54</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>1243.000000</td>\n",
              "      <td>122.450000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>225.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2090</td>\n",
              "      <td>D</td>\n",
              "      <td>Placebo</td>\n",
              "      <td>16467</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>0.7</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>3.74</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>1024.000000</td>\n",
              "      <td>77.500000</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>151.0</td>\n",
              "      <td>10.2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2105</td>\n",
              "      <td>D</td>\n",
              "      <td>Placebo</td>\n",
              "      <td>21699</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>1.9</td>\n",
              "      <td>486.000000</td>\n",
              "      <td>3.54</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>1052.000000</td>\n",
              "      <td>108.500000</td>\n",
              "      <td>109.000000</td>\n",
              "      <td>151.0</td>\n",
              "      <td>11.5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9634</th>\n",
              "      <td>24963</td>\n",
              "      <td>3577</td>\n",
              "      <td>C</td>\n",
              "      <td>Placebo</td>\n",
              "      <td>17897</td>\n",
              "      <td>F</td>\n",
              "      <td>Y</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>N</td>\n",
              "      <td>0.7</td>\n",
              "      <td>369.510563</td>\n",
              "      <td>3.49</td>\n",
              "      <td>97.648387</td>\n",
              "      <td>1982.655769</td>\n",
              "      <td>122.556346</td>\n",
              "      <td>124.702128</td>\n",
              "      <td>243.0</td>\n",
              "      <td>9.7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9635</th>\n",
              "      <td>24971</td>\n",
              "      <td>4795</td>\n",
              "      <td>C</td>\n",
              "      <td>Placebo</td>\n",
              "      <td>23376</td>\n",
              "      <td>F</td>\n",
              "      <td>Y</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>N</td>\n",
              "      <td>1.8</td>\n",
              "      <td>369.510563</td>\n",
              "      <td>3.24</td>\n",
              "      <td>97.648387</td>\n",
              "      <td>1982.655769</td>\n",
              "      <td>122.556346</td>\n",
              "      <td>124.702128</td>\n",
              "      <td>139.0</td>\n",
              "      <td>10.5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9636</th>\n",
              "      <td>24972</td>\n",
              "      <td>3358</td>\n",
              "      <td>D</td>\n",
              "      <td>D-penicillamine</td>\n",
              "      <td>24585</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>2.1</td>\n",
              "      <td>262.000000</td>\n",
              "      <td>3.48</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>2045.000000</td>\n",
              "      <td>89.900000</td>\n",
              "      <td>84.000000</td>\n",
              "      <td>412.0</td>\n",
              "      <td>11.8</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9637</th>\n",
              "      <td>24991</td>\n",
              "      <td>4365</td>\n",
              "      <td>C</td>\n",
              "      <td>D-penicillamine</td>\n",
              "      <td>21324</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>0.9</td>\n",
              "      <td>346.000000</td>\n",
              "      <td>3.40</td>\n",
              "      <td>81.000000</td>\n",
              "      <td>1098.000000</td>\n",
              "      <td>122.450000</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>228.0</td>\n",
              "      <td>10.3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9638</th>\n",
              "      <td>24992</td>\n",
              "      <td>694</td>\n",
              "      <td>D</td>\n",
              "      <td>D-penicillamine</td>\n",
              "      <td>28650</td>\n",
              "      <td>M</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>N</td>\n",
              "      <td>0.8</td>\n",
              "      <td>300.000000</td>\n",
              "      <td>2.94</td>\n",
              "      <td>231.000000</td>\n",
              "      <td>1794.000000</td>\n",
              "      <td>130.200000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>97.0</td>\n",
              "      <td>11.2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9639 rows × 20 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0d1889c9-cad3-4380-a221-13dfb19949bb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0d1889c9-cad3-4380-a221-13dfb19949bb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0d1889c9-cad3-4380-a221-13dfb19949bb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bf6df6dd-5b0a-42c4-942a-dffbbc721c3c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bf6df6dd-5b0a-42c4-942a-dffbbc721c3c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bf6df6dd-5b0a-42c4-942a-dffbbc721c3c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_be79f9d2-217f-447f-9252-4a85610b98ba\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('liver_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_be79f9d2-217f-447f-9252-4a85610b98ba button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('liver_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "liver_df",
              "summary": "{\n  \"name\": \"liver_df\",\n  \"rows\": 9639,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6332,\n        \"min\": 0,\n        \"max\": 24992,\n        \"num_unique_values\": 9639,\n        \"samples\": [\n          12789,\n          811,\n          6264\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"N_Days\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1093,\n        \"min\": 41,\n        \"max\": 4795,\n        \"num_unique_values\": 549,\n        \"samples\": [\n          2666,\n          1504,\n          2507\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Status\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"C\",\n          \"D\",\n          \"CL\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Drug\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"D-penicillamine\",\n          \"Placebo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3693,\n        \"min\": 9598,\n        \"max\": 28650,\n        \"num_unique_values\": 510,\n        \"samples\": [\n          18295,\n          19699\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sex\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"M\",\n          \"F\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ascites\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Y\",\n          \"N\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hepatomegaly\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"N\",\n          \"Y\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Spiders\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Y\",\n          \"N\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Edema\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"N\",\n          \"Y\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Bilirubin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.51227754277262,\n        \"min\": 0.3,\n        \"max\": 28.0,\n        \"num_unique_values\": 113,\n        \"samples\": [\n          13.6,\n          12.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cholesterol\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 197.82433880807596,\n        \"min\": 120.0,\n        \"max\": 1775.0,\n        \"num_unique_values\": 220,\n        \"samples\": [\n          261.0,\n          288.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Albumin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.38231917674497445,\n        \"min\": 1.96,\n        \"max\": 4.64,\n        \"num_unique_values\": 179,\n        \"samples\": [\n          3.31,\n          3.77\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Copper\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 73.1088540997786,\n        \"min\": 4.0,\n        \"max\": 588.0,\n        \"num_unique_values\": 197,\n        \"samples\": [\n          243.0,\n          57.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Alk_Phos\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1827.063379559018,\n        \"min\": 289.0,\n        \"max\": 13862.4,\n        \"num_unique_values\": 336,\n        \"samples\": [\n          1911.0,\n          11320.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SGOT\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 47.653515000511725,\n        \"min\": 26.35,\n        \"max\": 457.25,\n        \"num_unique_values\": 240,\n        \"samples\": [\n          170.5,\n          85.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tryglicerides\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 55.20630063259935,\n        \"min\": 33.0,\n        \"max\": 598.0,\n        \"num_unique_values\": 157,\n        \"samples\": [\n          188.0,\n          71.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Platelets\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 95.74070015081811,\n        \"min\": 62.0,\n        \"max\": 721.0,\n        \"num_unique_values\": 295,\n        \"samples\": [\n          473.0,\n          270.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Prothrombin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9220260480469411,\n        \"min\": 9.0,\n        \"max\": 18.0,\n        \"num_unique_values\": 51,\n        \"samples\": [\n          9.0,\n          12.7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Stage\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 94
        }
      ],
      "source": [
        "# Read in the liver_clean.csv\n",
        "liver_df = pd.read_csv(\"/content/liver_clean.csv\")\n",
        "liver_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "mi4nA1iwv20t",
        "outputId": "94bab439-24b6-45fb-ab8c-235061759180"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   N_Days Status     Drug    Age Sex Ascites Hepatomegaly Spiders Edema  \\\n",
              "0    2221      C  Placebo  18499   F       N            Y       N     N   \n",
              "1    1230      C  Placebo  19724   M       Y            N       Y     N   \n",
              "2    4184      C  Placebo  11839   F       N            N       N     N   \n",
              "3    2090      D  Placebo  16467   F       N            N       N     N   \n",
              "4    2105      D  Placebo  21699   F       N            Y       N     N   \n",
              "\n",
              "   Bilirubin  Cholesterol  Albumin  Copper  Alk_Phos    SGOT  Tryglicerides  \\\n",
              "0        0.5        149.0     4.04   227.0     598.0   52.70           57.0   \n",
              "1        0.5        219.0     3.93    22.0     663.0   45.00           75.0   \n",
              "2        0.5        320.0     3.54    51.0    1243.0  122.45           80.0   \n",
              "3        0.7        255.0     3.74    23.0    1024.0   77.50           58.0   \n",
              "4        1.9        486.0     3.54    74.0    1052.0  108.50          109.0   \n",
              "\n",
              "   Platelets  Prothrombin  Stage  \n",
              "0      256.0          9.9      1  \n",
              "1      220.0         10.8      2  \n",
              "2      225.0         10.0      2  \n",
              "3      151.0         10.2      2  \n",
              "4      151.0         11.5      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-00c3d856-cf77-4dbe-abb9-524b5a7dfafa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>N_Days</th>\n",
              "      <th>Status</th>\n",
              "      <th>Drug</th>\n",
              "      <th>Age</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Ascites</th>\n",
              "      <th>Hepatomegaly</th>\n",
              "      <th>Spiders</th>\n",
              "      <th>Edema</th>\n",
              "      <th>Bilirubin</th>\n",
              "      <th>Cholesterol</th>\n",
              "      <th>Albumin</th>\n",
              "      <th>Copper</th>\n",
              "      <th>Alk_Phos</th>\n",
              "      <th>SGOT</th>\n",
              "      <th>Tryglicerides</th>\n",
              "      <th>Platelets</th>\n",
              "      <th>Prothrombin</th>\n",
              "      <th>Stage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2221</td>\n",
              "      <td>C</td>\n",
              "      <td>Placebo</td>\n",
              "      <td>18499</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>0.5</td>\n",
              "      <td>149.0</td>\n",
              "      <td>4.04</td>\n",
              "      <td>227.0</td>\n",
              "      <td>598.0</td>\n",
              "      <td>52.70</td>\n",
              "      <td>57.0</td>\n",
              "      <td>256.0</td>\n",
              "      <td>9.9</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1230</td>\n",
              "      <td>C</td>\n",
              "      <td>Placebo</td>\n",
              "      <td>19724</td>\n",
              "      <td>M</td>\n",
              "      <td>Y</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>N</td>\n",
              "      <td>0.5</td>\n",
              "      <td>219.0</td>\n",
              "      <td>3.93</td>\n",
              "      <td>22.0</td>\n",
              "      <td>663.0</td>\n",
              "      <td>45.00</td>\n",
              "      <td>75.0</td>\n",
              "      <td>220.0</td>\n",
              "      <td>10.8</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4184</td>\n",
              "      <td>C</td>\n",
              "      <td>Placebo</td>\n",
              "      <td>11839</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>0.5</td>\n",
              "      <td>320.0</td>\n",
              "      <td>3.54</td>\n",
              "      <td>51.0</td>\n",
              "      <td>1243.0</td>\n",
              "      <td>122.45</td>\n",
              "      <td>80.0</td>\n",
              "      <td>225.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2090</td>\n",
              "      <td>D</td>\n",
              "      <td>Placebo</td>\n",
              "      <td>16467</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>0.7</td>\n",
              "      <td>255.0</td>\n",
              "      <td>3.74</td>\n",
              "      <td>23.0</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>77.50</td>\n",
              "      <td>58.0</td>\n",
              "      <td>151.0</td>\n",
              "      <td>10.2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2105</td>\n",
              "      <td>D</td>\n",
              "      <td>Placebo</td>\n",
              "      <td>21699</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>1.9</td>\n",
              "      <td>486.0</td>\n",
              "      <td>3.54</td>\n",
              "      <td>74.0</td>\n",
              "      <td>1052.0</td>\n",
              "      <td>108.50</td>\n",
              "      <td>109.0</td>\n",
              "      <td>151.0</td>\n",
              "      <td>11.5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-00c3d856-cf77-4dbe-abb9-524b5a7dfafa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-00c3d856-cf77-4dbe-abb9-524b5a7dfafa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-00c3d856-cf77-4dbe-abb9-524b5a7dfafa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4dd3a75b-7606-4fc1-ad6e-027574c0dd3f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4dd3a75b-7606-4fc1-ad6e-027574c0dd3f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4dd3a75b-7606-4fc1-ad6e-027574c0dd3f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "liver_clean_df",
              "summary": "{\n  \"name\": \"liver_clean_df\",\n  \"rows\": 9639,\n  \"fields\": [\n    {\n      \"column\": \"N_Days\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1093,\n        \"min\": 41,\n        \"max\": 4795,\n        \"num_unique_values\": 549,\n        \"samples\": [\n          2666,\n          1504,\n          2507\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Status\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"C\",\n          \"D\",\n          \"CL\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Drug\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"D-penicillamine\",\n          \"Placebo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3693,\n        \"min\": 9598,\n        \"max\": 28650,\n        \"num_unique_values\": 510,\n        \"samples\": [\n          18295,\n          19699\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sex\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"M\",\n          \"F\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ascites\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Y\",\n          \"N\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hepatomegaly\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"N\",\n          \"Y\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Spiders\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Y\",\n          \"N\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Edema\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"N\",\n          \"Y\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Bilirubin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.51227754277262,\n        \"min\": 0.3,\n        \"max\": 28.0,\n        \"num_unique_values\": 113,\n        \"samples\": [\n          13.6,\n          12.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cholesterol\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 197.82433880807596,\n        \"min\": 120.0,\n        \"max\": 1775.0,\n        \"num_unique_values\": 220,\n        \"samples\": [\n          261.0,\n          288.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Albumin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.38231917674497445,\n        \"min\": 1.96,\n        \"max\": 4.64,\n        \"num_unique_values\": 179,\n        \"samples\": [\n          3.31,\n          3.77\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Copper\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 73.1088540997786,\n        \"min\": 4.0,\n        \"max\": 588.0,\n        \"num_unique_values\": 197,\n        \"samples\": [\n          243.0,\n          57.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Alk_Phos\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1827.063379559018,\n        \"min\": 289.0,\n        \"max\": 13862.4,\n        \"num_unique_values\": 336,\n        \"samples\": [\n          1911.0,\n          11320.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SGOT\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 47.653515000511725,\n        \"min\": 26.35,\n        \"max\": 457.25,\n        \"num_unique_values\": 240,\n        \"samples\": [\n          170.5,\n          85.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tryglicerides\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 55.20630063259935,\n        \"min\": 33.0,\n        \"max\": 598.0,\n        \"num_unique_values\": 157,\n        \"samples\": [\n          188.0,\n          71.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Platelets\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 95.74070015081811,\n        \"min\": 62.0,\n        \"max\": 721.0,\n        \"num_unique_values\": 295,\n        \"samples\": [\n          473.0,\n          270.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Prothrombin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9220260480469411,\n        \"min\": 9.0,\n        \"max\": 18.0,\n        \"num_unique_values\": 51,\n        \"samples\": [\n          9.0,\n          12.7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Stage\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 95
        }
      ],
      "source": [
        "#drop the \"unnamed: 0\" uneccesary index column\n",
        "liver_clean_df=liver_df.drop(columns=[\"Unnamed: 0\"])\n",
        "\n",
        "liver_clean_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1z4zuJlwsDQ",
        "outputId": "8d72e434-bb75-41b9-f4ed-5739d6fad104"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       1\n",
              "1       2\n",
              "2       2\n",
              "3       2\n",
              "4       1\n",
              "       ..\n",
              "9634    1\n",
              "9635    1\n",
              "9636    3\n",
              "9637    2\n",
              "9638    3\n",
              "Name: Stage, Length: 9639, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "source": [
        "liver_clean_df['Stage']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "toQ13AtZrxVZ"
      },
      "outputs": [],
      "source": [
        "# Generate categorical variable lists\n",
        "liver_clean_cat = liver_clean_df.dtypes[liver_clean_df.dtypes == \"object\"].index.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNgS91Ocrxul",
        "outputId": "05788080-09c8-4c6d-8823-fea676cbd725"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Status', 'Drug', 'Sex', 'Ascites', 'Hepatomegaly', 'Spiders', 'Edema']\n"
          ]
        }
      ],
      "source": [
        "#Print liver_clean_cat list\n",
        "print(liver_clean_cat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpGTW-JmrxjE",
        "outputId": "f364c7e6-3d43-4530-fe61-342d2d060502"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Status          3\n",
              "Drug            2\n",
              "Sex             2\n",
              "Ascites         2\n",
              "Hepatomegaly    2\n",
              "Spiders         2\n",
              "Edema           3\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ],
      "source": [
        "# Check number of unique values in each column\n",
        "liver_clean_df[liver_clean_cat].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "6jTsIElliptM",
        "outputId": "479e3628-5279-474f-bd2b-6311364eb896"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Status_C  Status_CL  Status_D  Drug_D-penicillamine  Drug_Placebo  Sex_F  \\\n",
              "0       1.0        0.0       0.0                   0.0           1.0    1.0   \n",
              "1       1.0        0.0       0.0                   0.0           1.0    0.0   \n",
              "2       1.0        0.0       0.0                   0.0           1.0    1.0   \n",
              "3       0.0        0.0       1.0                   0.0           1.0    1.0   \n",
              "4       0.0        0.0       1.0                   0.0           1.0    1.0   \n",
              "\n",
              "   Sex_M  Ascites_N  Ascites_Y  Hepatomegaly_N  Hepatomegaly_Y  Spiders_N  \\\n",
              "0    0.0        1.0        0.0             0.0             1.0        1.0   \n",
              "1    1.0        0.0        1.0             1.0             0.0        0.0   \n",
              "2    0.0        1.0        0.0             1.0             0.0        1.0   \n",
              "3    0.0        1.0        0.0             1.0             0.0        1.0   \n",
              "4    0.0        1.0        0.0             0.0             1.0        1.0   \n",
              "\n",
              "   Spiders_Y  Edema_N  Edema_S  Edema_Y  \n",
              "0        0.0      1.0      0.0      0.0  \n",
              "1        1.0      1.0      0.0      0.0  \n",
              "2        0.0      1.0      0.0      0.0  \n",
              "3        0.0      1.0      0.0      0.0  \n",
              "4        0.0      1.0      0.0      0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d46c8685-54a5-4e85-a207-53e3512228cf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Status_C</th>\n",
              "      <th>Status_CL</th>\n",
              "      <th>Status_D</th>\n",
              "      <th>Drug_D-penicillamine</th>\n",
              "      <th>Drug_Placebo</th>\n",
              "      <th>Sex_F</th>\n",
              "      <th>Sex_M</th>\n",
              "      <th>Ascites_N</th>\n",
              "      <th>Ascites_Y</th>\n",
              "      <th>Hepatomegaly_N</th>\n",
              "      <th>Hepatomegaly_Y</th>\n",
              "      <th>Spiders_N</th>\n",
              "      <th>Spiders_Y</th>\n",
              "      <th>Edema_N</th>\n",
              "      <th>Edema_S</th>\n",
              "      <th>Edema_Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d46c8685-54a5-4e85-a207-53e3512228cf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d46c8685-54a5-4e85-a207-53e3512228cf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d46c8685-54a5-4e85-a207-53e3512228cf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-652a5f32-7417-497f-9055-37087245910e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-652a5f32-7417-497f-9055-37087245910e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-652a5f32-7417-497f-9055-37087245910e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "encode_df",
              "summary": "{\n  \"name\": \"encode_df\",\n  \"rows\": 9639,\n  \"fields\": [\n    {\n      \"column\": \"Status_C\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.49726790008864746,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Status_CL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.24330053860864775,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Status_D\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4864726468951137,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Drug_D-penicillamine\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4786998866262104,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Drug_Placebo\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4786998866262103,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sex_F\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.315310296963102,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sex_M\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.315310296963102,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ascites_N\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.47486711313038,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ascites_Y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.47486711313038,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hepatomegaly_N\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4872019595310808,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hepatomegaly_Y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.48720195953108086,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Spiders_N\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4998134165022733,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Spiders_Y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4998134165022733,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Edema_N\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.370596155649565,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Edema_S\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3333208358818645,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Edema_Y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1888623716140423,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 100
        }
      ],
      "source": [
        "# Create OneHotEncoder instance\n",
        "enc = OneHotEncoder(sparse=False)\n",
        "\n",
        "# Fit and transform OneHotEncoder using categorical variable list\n",
        "# Result is stored in new DataFrame called encode_df\n",
        "encode_df = pd.DataFrame(enc.fit_transform(liver_clean_df[liver_clean_cat]))\n",
        "\n",
        "# Add encoded variable names to encode_df dataframe\n",
        "# Assign encoded variable names to columns of encode_df DataFrame\n",
        "# get_feature_names_out method retrieves feature names for encoded categorical variables\n",
        "encode_df.columns = enc.get_feature_names_out(liver_clean_cat)\n",
        "\n",
        "#print\n",
        "encode_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLfUJUhkipof",
        "outputId": "9c3f13d9-4788-475c-c67a-d743846d01f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['N_Days', 'Status', 'Drug', 'Age', 'Sex', 'Ascites', 'Hepatomegaly', 'Spiders', 'Edema', 'Bilirubin', 'Cholesterol', 'Albumin', 'Copper', 'Alk_Phos', 'SGOT', 'Tryglicerides', 'Platelets', 'Prothrombin', 'Stage']\n"
          ]
        }
      ],
      "source": [
        "#Get liver_clean_df column names into list form\n",
        "liver_list = liver_clean_df.columns.tolist()\n",
        "print(liver_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9m6t5nripiK",
        "outputId": "8f1eebcf-6162-4dd4-81c3-085d74d865a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Status_C', 'Status_CL', 'Status_D', 'Drug_D-penicillamine', 'Drug_Placebo', 'Sex_F', 'Sex_M', 'Ascites_N', 'Ascites_Y', 'Hepatomegaly_N', 'Hepatomegaly_Y', 'Spiders_N', 'Spiders_Y', 'Edema_N', 'Edema_S', 'Edema_Y']\n"
          ]
        }
      ],
      "source": [
        "#Get encode_df column names into list form\n",
        "column_list = encode_df.columns.tolist()\n",
        "print(column_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "GRfgSvsTipbC",
        "outputId": "1cc4ee22-9e7c-42fb-aa0c-a36b2cac8b4f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   N_Days    Age  Bilirubin  Cholesterol  Albumin  Copper  Alk_Phos    SGOT  \\\n",
              "0    2221  18499        0.5        149.0     4.04   227.0     598.0   52.70   \n",
              "1    1230  19724        0.5        219.0     3.93    22.0     663.0   45.00   \n",
              "2    4184  11839        0.5        320.0     3.54    51.0    1243.0  122.45   \n",
              "3    2090  16467        0.7        255.0     3.74    23.0    1024.0   77.50   \n",
              "4    2105  21699        1.9        486.0     3.54    74.0    1052.0  108.50   \n",
              "\n",
              "   Tryglicerides  Platelets  ...  Sex_M  Ascites_N  Ascites_Y  Hepatomegaly_N  \\\n",
              "0           57.0      256.0  ...    0.0        1.0        0.0             0.0   \n",
              "1           75.0      220.0  ...    1.0        0.0        1.0             1.0   \n",
              "2           80.0      225.0  ...    0.0        1.0        0.0             1.0   \n",
              "3           58.0      151.0  ...    0.0        1.0        0.0             1.0   \n",
              "4          109.0      151.0  ...    0.0        1.0        0.0             0.0   \n",
              "\n",
              "   Hepatomegaly_Y  Spiders_N  Spiders_Y  Edema_N  Edema_S  Edema_Y  \n",
              "0             1.0        1.0        0.0      1.0      0.0      0.0  \n",
              "1             0.0        0.0        1.0      1.0      0.0      0.0  \n",
              "2             0.0        1.0        0.0      1.0      0.0      0.0  \n",
              "3             0.0        1.0        0.0      1.0      0.0      0.0  \n",
              "4             1.0        1.0        0.0      1.0      0.0      0.0  \n",
              "\n",
              "[5 rows x 28 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-58d513c2-754b-48d8-8676-888eaa521fa7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>N_Days</th>\n",
              "      <th>Age</th>\n",
              "      <th>Bilirubin</th>\n",
              "      <th>Cholesterol</th>\n",
              "      <th>Albumin</th>\n",
              "      <th>Copper</th>\n",
              "      <th>Alk_Phos</th>\n",
              "      <th>SGOT</th>\n",
              "      <th>Tryglicerides</th>\n",
              "      <th>Platelets</th>\n",
              "      <th>...</th>\n",
              "      <th>Sex_M</th>\n",
              "      <th>Ascites_N</th>\n",
              "      <th>Ascites_Y</th>\n",
              "      <th>Hepatomegaly_N</th>\n",
              "      <th>Hepatomegaly_Y</th>\n",
              "      <th>Spiders_N</th>\n",
              "      <th>Spiders_Y</th>\n",
              "      <th>Edema_N</th>\n",
              "      <th>Edema_S</th>\n",
              "      <th>Edema_Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2221</td>\n",
              "      <td>18499</td>\n",
              "      <td>0.5</td>\n",
              "      <td>149.0</td>\n",
              "      <td>4.04</td>\n",
              "      <td>227.0</td>\n",
              "      <td>598.0</td>\n",
              "      <td>52.70</td>\n",
              "      <td>57.0</td>\n",
              "      <td>256.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1230</td>\n",
              "      <td>19724</td>\n",
              "      <td>0.5</td>\n",
              "      <td>219.0</td>\n",
              "      <td>3.93</td>\n",
              "      <td>22.0</td>\n",
              "      <td>663.0</td>\n",
              "      <td>45.00</td>\n",
              "      <td>75.0</td>\n",
              "      <td>220.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4184</td>\n",
              "      <td>11839</td>\n",
              "      <td>0.5</td>\n",
              "      <td>320.0</td>\n",
              "      <td>3.54</td>\n",
              "      <td>51.0</td>\n",
              "      <td>1243.0</td>\n",
              "      <td>122.45</td>\n",
              "      <td>80.0</td>\n",
              "      <td>225.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2090</td>\n",
              "      <td>16467</td>\n",
              "      <td>0.7</td>\n",
              "      <td>255.0</td>\n",
              "      <td>3.74</td>\n",
              "      <td>23.0</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>77.50</td>\n",
              "      <td>58.0</td>\n",
              "      <td>151.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2105</td>\n",
              "      <td>21699</td>\n",
              "      <td>1.9</td>\n",
              "      <td>486.0</td>\n",
              "      <td>3.54</td>\n",
              "      <td>74.0</td>\n",
              "      <td>1052.0</td>\n",
              "      <td>108.50</td>\n",
              "      <td>109.0</td>\n",
              "      <td>151.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 28 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-58d513c2-754b-48d8-8676-888eaa521fa7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-58d513c2-754b-48d8-8676-888eaa521fa7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-58d513c2-754b-48d8-8676-888eaa521fa7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-009db9a9-cfaf-49e2-b9f6-327a9c4791f7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-009db9a9-cfaf-49e2-b9f6-327a9c4791f7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-009db9a9-cfaf-49e2-b9f6-327a9c4791f7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "liver_clean_df"
            }
          },
          "metadata": {},
          "execution_count": 103
        }
      ],
      "source": [
        "#Merge one-hot encoded features and drop original features\n",
        "\n",
        "#Merge encoded features, encode_df, with original dataframe, liver_clean_df, into liver_clean_df\n",
        "#left_index=True and right_index=True parameters indicate that merge is based on index of DataFrames\n",
        "liver_clean_df = liver_clean_df.merge(encode_df, left_index=True, right_index=True)\n",
        "\n",
        "#Drop original categorical columns, collected in liver_lean_cat, from liver_clean_df\n",
        "#axis=1 parameter specifies columns (not rows) should be dropped\n",
        "liver_clean_df = liver_clean_df.drop(liver_clean_cat, axis=1)\n",
        "\n",
        "liver_clean_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeGylwNaipTr",
        "outputId": "14c673c4-4df3-4906-cbdd-cdc6068c5e87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of features in the DataFrame: 28\n"
          ]
        }
      ],
      "source": [
        "# Get number of columns (features)\n",
        "num_features = liver_clean_df.shape[1]\n",
        "print(\"Number of features in the DataFrame:\", num_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "HqVIWu-6ipLc"
      },
      "outputs": [],
      "source": [
        "#Define X and y\n",
        "X=liver_clean_df.drop([\"Stage\"],axis=1)\n",
        "y=liver_clean_df[[\"Stage\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "wuI2vtDcEbQ6"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "z50dFnNyipCZ"
      },
      "outputs": [],
      "source": [
        "# Split preprocessed data into training and testing datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.2, random_state=78)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "G_wTaV3GkCB-"
      },
      "outputs": [],
      "source": [
        "# Create StandardScaler instances\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "fuoDm3y2kB5w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4af6e9e1-6cc0-4a77-9cbc-65d4b4e1e272"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.47478759  1.91977093 -0.58030606 ...  0.44623851 -0.39140986\n",
            "  -0.18534615]\n",
            " [-0.54840842  1.50485971  0.74594393 ...  0.44623851 -0.39140986\n",
            "  -0.18534615]\n",
            " [-0.85620447 -0.37584224  1.71852725 ...  0.44623851 -0.39140986\n",
            "  -0.18534615]\n",
            " ...\n",
            " [ 0.46882    -0.01137535  0.61331893 ...  0.44623851 -0.39140986\n",
            "  -0.18534615]\n",
            " [ 0.78318487 -0.89745246  0.54700643 ...  0.44623851 -0.39140986\n",
            "  -0.18534615]\n",
            " [ 0.9014236   0.12939338 -0.44768106 ...  0.44623851 -0.39140986\n",
            "  -0.18534615]]\n"
          ]
        }
      ],
      "source": [
        "print(X_train_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "6VT4QL-QkBwZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5ff0f4d-e894-4623-8f1c-1316ad048a55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2.46104872 -0.93178629 -0.5582019  ...  0.44623851 -0.39140986\n",
            "  -0.18534615]\n",
            " [-1.19684462  0.25537215 -0.27084773 ... -2.24095404  2.55486668\n",
            "  -0.18534615]\n",
            " [ 1.27396943 -0.16350066  0.01650643 ...  0.44623851 -0.39140986\n",
            "  -0.18534615]\n",
            " ...\n",
            " [ 2.01343068  1.80567694 -0.6245144  ...  0.44623851 -0.39140986\n",
            "  -0.18534615]\n",
            " [ 1.03561517 -1.13224308 -0.46978523 ...  0.44623851 -0.39140986\n",
            "  -0.18534615]\n",
            " [ 0.12724145 -1.51176403 -0.5582019  ...  0.44623851 -0.39140986\n",
            "  -0.18534615]]\n"
          ]
        }
      ],
      "source": [
        "print(X_test_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "2D_mVl5ikBnC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dce4e915-e0c3-43bb-bdab-7696b038d4a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "#Verify type of X_train_scaled to ensure it is list or array\n",
        "print(type(X_train_scaled))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "8rBc_uBzw33o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7228fb6b-afaa-40b3-84dc-b3420357f69e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "#Verify type of X_test_scaled to ensure it is list or array\n",
        "print(type(X_test_scaled))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Improved Neural Network Model"
      ],
      "metadata": {
        "id": "2BuV6MfFHwEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model to be deep neural net\n",
        "\n",
        "#calculate number of input features in dataset based on first row of input features (X_train_array)\n",
        "number_input_features = X_train_scaled.shape[1]\n",
        "hidden_nodes_layer1 =  27\n",
        "hidden_nodes_layer2 = 35\n",
        "hidden_nodes_layer3 = 35\n",
        "\n",
        "\n",
        "#Create Keras Sequantial model\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
        "\n",
        "# Third hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=3, activation=\"softmax\"))\n",
        "\n",
        "# Check structure of model\n",
        "nn.summary()\n"
      ],
      "metadata": {
        "id": "Cz_ds7NzH0YC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38898945-7dc9-4cff-c4a4-02fc3d4465b7"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 27)                756       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 35)                980       \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 35)                1260      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 3)                 108       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3104 (12.12 KB)\n",
            "Trainable params: 3104 (12.12 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "nn.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
        "\n",
        "# nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "yH80z4O-IEpT"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import tensorflow as tf\n",
        "\n",
        "# One-hot encode the target variable y_train\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "\n",
        "# Convert DataFrame to numpy array before reshaping\n",
        "y_train_array = y_train.to_numpy()\n",
        "\n",
        "# One-hot encode the target variable y_train\n",
        "y_train_encoded = encoder.fit_transform(y_train_array.reshape(-1, 1))\n",
        "\n",
        "\n",
        "# Create and compile your neural network model\n",
        "# Define your model architecture here\n",
        "\n",
        "# Compile the model\n",
        "nn.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "fit_model = nn.fit(X_train_scaled, y_train_encoded, epochs=1000)"
      ],
      "metadata": {
        "id": "71pJODSoIHjF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df489bb6-3ba3-49a7-ba4a-df79f09ebb39"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "61/61 [==============================] - 6s 8ms/step - loss: 1.0424 - accuracy: 0.4504\n",
            "Epoch 2/1000\n",
            "61/61 [==============================] - 0s 6ms/step - loss: 0.9390 - accuracy: 0.5418\n",
            "Epoch 3/1000\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 0.8980 - accuracy: 0.5677\n",
            "Epoch 4/1000\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.8701 - accuracy: 0.5880\n",
            "Epoch 5/1000\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 0.8470 - accuracy: 0.5963\n",
            "Epoch 6/1000\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.8308 - accuracy: 0.6144\n",
            "Epoch 7/1000\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.8129 - accuracy: 0.6160\n",
            "Epoch 8/1000\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.7997 - accuracy: 0.6274\n",
            "Epoch 9/1000\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 0.7851 - accuracy: 0.6419\n",
            "Epoch 10/1000\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 0.7664 - accuracy: 0.6523\n",
            "Epoch 11/1000\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.7578 - accuracy: 0.6591\n",
            "Epoch 12/1000\n",
            "61/61 [==============================] - 0s 6ms/step - loss: 0.7412 - accuracy: 0.6632\n",
            "Epoch 13/1000\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 0.7290 - accuracy: 0.6767\n",
            "Epoch 14/1000\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 0.7174 - accuracy: 0.6809\n",
            "Epoch 15/1000\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.6987 - accuracy: 0.6917\n",
            "Epoch 16/1000\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.6877 - accuracy: 0.6954\n",
            "Epoch 17/1000\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.6748 - accuracy: 0.7037\n",
            "Epoch 18/1000\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.6587 - accuracy: 0.7167\n",
            "Epoch 19/1000\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 0.6555 - accuracy: 0.7089\n",
            "Epoch 20/1000\n",
            "61/61 [==============================] - 0s 7ms/step - loss: 0.6370 - accuracy: 0.7338\n",
            "Epoch 21/1000\n",
            "61/61 [==============================] - 0s 7ms/step - loss: 0.6273 - accuracy: 0.7276\n",
            "Epoch 22/1000\n",
            "61/61 [==============================] - 0s 7ms/step - loss: 0.6166 - accuracy: 0.7379\n",
            "Epoch 23/1000\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 0.6041 - accuracy: 0.7395\n",
            "Epoch 24/1000\n",
            "61/61 [==============================] - 0s 5ms/step - loss: 0.5953 - accuracy: 0.7457\n",
            "Epoch 25/1000\n",
            "61/61 [==============================] - 0s 5ms/step - loss: 0.5902 - accuracy: 0.7488\n",
            "Epoch 26/1000\n",
            "61/61 [==============================] - 0s 6ms/step - loss: 0.5706 - accuracy: 0.7654\n",
            "Epoch 27/1000\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.5606 - accuracy: 0.7691\n",
            "Epoch 28/1000\n",
            "61/61 [==============================] - 0s 7ms/step - loss: 0.5508 - accuracy: 0.7732\n",
            "Epoch 29/1000\n",
            "61/61 [==============================] - 0s 5ms/step - loss: 0.5424 - accuracy: 0.7820\n",
            "Epoch 30/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.5364 - accuracy: 0.7717\n",
            "Epoch 31/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.5293 - accuracy: 0.7826\n",
            "Epoch 32/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.5178 - accuracy: 0.7935\n",
            "Epoch 33/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.5092 - accuracy: 0.7940\n",
            "Epoch 34/1000\n",
            "61/61 [==============================] - 0s 5ms/step - loss: 0.4966 - accuracy: 0.7997\n",
            "Epoch 35/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.4907 - accuracy: 0.8085\n",
            "Epoch 36/1000\n",
            "61/61 [==============================] - 0s 6ms/step - loss: 0.4824 - accuracy: 0.8085\n",
            "Epoch 37/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.4801 - accuracy: 0.8106\n",
            "Epoch 38/1000\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.4693 - accuracy: 0.8179\n",
            "Epoch 39/1000\n",
            "61/61 [==============================] - 0s 5ms/step - loss: 0.4634 - accuracy: 0.8194\n",
            "Epoch 40/1000\n",
            "61/61 [==============================] - 0s 6ms/step - loss: 0.4604 - accuracy: 0.8132\n",
            "Epoch 41/1000\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.4481 - accuracy: 0.8272\n",
            "Epoch 42/1000\n",
            "61/61 [==============================] - 0s 6ms/step - loss: 0.4366 - accuracy: 0.8287\n",
            "Epoch 43/1000\n",
            "61/61 [==============================] - 0s 6ms/step - loss: 0.4318 - accuracy: 0.8329\n",
            "Epoch 44/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.8407\n",
            "Epoch 45/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.8391\n",
            "Epoch 46/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.4125 - accuracy: 0.8350\n",
            "Epoch 47/1000\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 0.4059 - accuracy: 0.8469\n",
            "Epoch 48/1000\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.4047 - accuracy: 0.8422\n",
            "Epoch 49/1000\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 0.4005 - accuracy: 0.8438\n",
            "Epoch 50/1000\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 0.3944 - accuracy: 0.8454\n",
            "Epoch 51/1000\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 0.3853 - accuracy: 0.8542\n",
            "Epoch 52/1000\n",
            "61/61 [==============================] - 0s 7ms/step - loss: 0.3790 - accuracy: 0.8604\n",
            "Epoch 53/1000\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 0.3764 - accuracy: 0.8640\n",
            "Epoch 54/1000\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.3701 - accuracy: 0.8656\n",
            "Epoch 55/1000\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.3585 - accuracy: 0.8635\n",
            "Epoch 56/1000\n",
            "61/61 [==============================] - 0s 6ms/step - loss: 0.3599 - accuracy: 0.8697\n",
            "Epoch 57/1000\n",
            "61/61 [==============================] - 0s 5ms/step - loss: 0.3566 - accuracy: 0.8640\n",
            "Epoch 58/1000\n",
            "61/61 [==============================] - 0s 5ms/step - loss: 0.3536 - accuracy: 0.8692\n",
            "Epoch 59/1000\n",
            "61/61 [==============================] - 0s 5ms/step - loss: 0.3385 - accuracy: 0.8749\n",
            "Epoch 60/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.3439 - accuracy: 0.8755\n",
            "Epoch 61/1000\n",
            "61/61 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.8760\n",
            "Epoch 62/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.3282 - accuracy: 0.8765\n",
            "Epoch 63/1000\n",
            "61/61 [==============================] - 0s 7ms/step - loss: 0.3251 - accuracy: 0.8874\n",
            "Epoch 64/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.3198 - accuracy: 0.8848\n",
            "Epoch 65/1000\n",
            "61/61 [==============================] - 0s 7ms/step - loss: 0.3174 - accuracy: 0.8801\n",
            "Epoch 66/1000\n",
            "61/61 [==============================] - 0s 6ms/step - loss: 0.3146 - accuracy: 0.8817\n",
            "Epoch 67/1000\n",
            "61/61 [==============================] - 0s 5ms/step - loss: 0.3037 - accuracy: 0.8884\n",
            "Epoch 68/1000\n",
            "61/61 [==============================] - 0s 6ms/step - loss: 0.3001 - accuracy: 0.8910\n",
            "Epoch 69/1000\n",
            "61/61 [==============================] - 0s 5ms/step - loss: 0.3004 - accuracy: 0.8915\n",
            "Epoch 70/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.2925 - accuracy: 0.9009\n",
            "Epoch 71/1000\n",
            "61/61 [==============================] - 0s 6ms/step - loss: 0.2890 - accuracy: 0.8972\n",
            "Epoch 72/1000\n",
            "61/61 [==============================] - 0s 5ms/step - loss: 0.2849 - accuracy: 0.8988\n",
            "Epoch 73/1000\n",
            "61/61 [==============================] - 0s 5ms/step - loss: 0.2826 - accuracy: 0.9035\n",
            "Epoch 74/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.2775 - accuracy: 0.9024\n",
            "Epoch 75/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.2748 - accuracy: 0.8988\n",
            "Epoch 76/1000\n",
            "61/61 [==============================] - 0s 6ms/step - loss: 0.2783 - accuracy: 0.9045\n",
            "Epoch 77/1000\n",
            "61/61 [==============================] - 0s 5ms/step - loss: 0.2698 - accuracy: 0.9030\n",
            "Epoch 78/1000\n",
            "61/61 [==============================] - 0s 5ms/step - loss: 0.2767 - accuracy: 0.8947\n",
            "Epoch 79/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.2641 - accuracy: 0.9066\n",
            "Epoch 80/1000\n",
            "61/61 [==============================] - 0s 6ms/step - loss: 0.2582 - accuracy: 0.9113\n",
            "Epoch 81/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.2536 - accuracy: 0.9087\n",
            "Epoch 82/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.2524 - accuracy: 0.9056\n",
            "Epoch 83/1000\n",
            "61/61 [==============================] - 0s 5ms/step - loss: 0.2506 - accuracy: 0.9118\n",
            "Epoch 84/1000\n",
            "61/61 [==============================] - 0s 6ms/step - loss: 0.2472 - accuracy: 0.9165\n",
            "Epoch 85/1000\n",
            "61/61 [==============================] - 0s 5ms/step - loss: 0.2404 - accuracy: 0.9201\n",
            "Epoch 86/1000\n",
            "61/61 [==============================] - 0s 5ms/step - loss: 0.2497 - accuracy: 0.9107\n",
            "Epoch 87/1000\n",
            "61/61 [==============================] - 0s 6ms/step - loss: 0.2365 - accuracy: 0.9232\n",
            "Epoch 88/1000\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.2327 - accuracy: 0.9222\n",
            "Epoch 89/1000\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.2301 - accuracy: 0.9232\n",
            "Epoch 90/1000\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.2360 - accuracy: 0.9159\n",
            "Epoch 91/1000\n",
            "61/61 [==============================] - 0s 5ms/step - loss: 0.2288 - accuracy: 0.9216\n",
            "Epoch 92/1000\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.2208 - accuracy: 0.9242\n",
            "Epoch 93/1000\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.2195 - accuracy: 0.9253\n",
            "Epoch 94/1000\n",
            "61/61 [==============================] - 0s 5ms/step - loss: 0.2161 - accuracy: 0.9268\n",
            "Epoch 95/1000\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.2206 - accuracy: 0.9284\n",
            "Epoch 96/1000\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 0.2123 - accuracy: 0.9258\n",
            "Epoch 97/1000\n",
            "61/61 [==============================] - 0s 6ms/step - loss: 0.2106 - accuracy: 0.9284\n",
            "Epoch 98/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.2156 - accuracy: 0.9253\n",
            "Epoch 99/1000\n",
            "61/61 [==============================] - 0s 6ms/step - loss: 0.2053 - accuracy: 0.9315\n",
            "Epoch 100/1000\n",
            "61/61 [==============================] - 0s 6ms/step - loss: 0.2004 - accuracy: 0.9382\n",
            "Epoch 101/1000\n",
            "61/61 [==============================] - 0s 6ms/step - loss: 0.2004 - accuracy: 0.9351\n",
            "Epoch 102/1000\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.2007 - accuracy: 0.9367\n",
            "Epoch 103/1000\n",
            "61/61 [==============================] - 0s 6ms/step - loss: 0.1973 - accuracy: 0.9367\n",
            "Epoch 104/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.1932 - accuracy: 0.9341\n",
            "Epoch 105/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.1868 - accuracy: 0.9408\n",
            "Epoch 106/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.1948 - accuracy: 0.9341\n",
            "Epoch 107/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.1873 - accuracy: 0.9398\n",
            "Epoch 108/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.1867 - accuracy: 0.9398\n",
            "Epoch 109/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.1898 - accuracy: 0.9377\n",
            "Epoch 110/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.1773 - accuracy: 0.9471\n",
            "Epoch 111/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.1796 - accuracy: 0.9455\n",
            "Epoch 112/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.1840 - accuracy: 0.9377\n",
            "Epoch 113/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.1772 - accuracy: 0.9460\n",
            "Epoch 114/1000\n",
            "61/61 [==============================] - 0s 6ms/step - loss: 0.1902 - accuracy: 0.9382\n",
            "Epoch 115/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.1746 - accuracy: 0.9414\n",
            "Epoch 116/1000\n",
            "61/61 [==============================] - 0s 5ms/step - loss: 0.1711 - accuracy: 0.9450\n",
            "Epoch 117/1000\n",
            "61/61 [==============================] - 0s 5ms/step - loss: 0.1748 - accuracy: 0.9424\n",
            "Epoch 118/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.1689 - accuracy: 0.9424\n",
            "Epoch 119/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.1629 - accuracy: 0.9497\n",
            "Epoch 120/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.1634 - accuracy: 0.9471\n",
            "Epoch 121/1000\n",
            "61/61 [==============================] - 0s 5ms/step - loss: 0.1596 - accuracy: 0.9512\n",
            "Epoch 122/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.1627 - accuracy: 0.9476\n",
            "Epoch 123/1000\n",
            "61/61 [==============================] - 0s 5ms/step - loss: 0.1548 - accuracy: 0.9549\n",
            "Epoch 124/1000\n",
            "61/61 [==============================] - 0s 5ms/step - loss: 0.1541 - accuracy: 0.9533\n",
            "Epoch 125/1000\n",
            "61/61 [==============================] - 0s 5ms/step - loss: 0.1588 - accuracy: 0.9455\n",
            "Epoch 126/1000\n",
            "61/61 [==============================] - 0s 5ms/step - loss: 0.1493 - accuracy: 0.9549\n",
            "Epoch 127/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.1510 - accuracy: 0.9533\n",
            "Epoch 128/1000\n",
            "61/61 [==============================] - 0s 5ms/step - loss: 0.1563 - accuracy: 0.9491\n",
            "Epoch 129/1000\n",
            "61/61 [==============================] - 0s 5ms/step - loss: 0.1462 - accuracy: 0.9549\n",
            "Epoch 130/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.1536 - accuracy: 0.9476\n",
            "Epoch 131/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.1484 - accuracy: 0.9512\n",
            "Epoch 132/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.1390 - accuracy: 0.9606\n",
            "Epoch 133/1000\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.1324 - accuracy: 0.9611\n",
            "Epoch 134/1000\n",
            "61/61 [==============================] - 0s 7ms/step - loss: 0.1465 - accuracy: 0.9533\n",
            "Epoch 135/1000\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.1379 - accuracy: 0.9632\n",
            "Epoch 136/1000\n",
            "61/61 [==============================] - 0s 6ms/step - loss: 0.1312 - accuracy: 0.9632\n",
            "Epoch 137/1000\n",
            "61/61 [==============================] - 0s 7ms/step - loss: 0.1347 - accuracy: 0.9626\n",
            "Epoch 138/1000\n",
            "61/61 [==============================] - 0s 6ms/step - loss: 0.1376 - accuracy: 0.9559\n",
            "Epoch 139/1000\n",
            "61/61 [==============================] - 0s 7ms/step - loss: 0.1270 - accuracy: 0.9621\n",
            "Epoch 140/1000\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.1374 - accuracy: 0.9564\n",
            "Epoch 141/1000\n",
            "61/61 [==============================] - 0s 7ms/step - loss: 0.1252 - accuracy: 0.9647\n",
            "Epoch 142/1000\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.1285 - accuracy: 0.9611\n",
            "Epoch 143/1000\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 0.1174 - accuracy: 0.9689\n",
            "Epoch 144/1000\n",
            "61/61 [==============================] - 0s 7ms/step - loss: 0.1211 - accuracy: 0.9632\n",
            "Epoch 145/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.1266 - accuracy: 0.9616\n",
            "Epoch 146/1000\n",
            "61/61 [==============================] - 0s 5ms/step - loss: 0.1139 - accuracy: 0.9699\n",
            "Epoch 147/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.1154 - accuracy: 0.9678\n",
            "Epoch 148/1000\n",
            "61/61 [==============================] - 0s 5ms/step - loss: 0.1135 - accuracy: 0.9668\n",
            "Epoch 149/1000\n",
            "61/61 [==============================] - 0s 6ms/step - loss: 0.1183 - accuracy: 0.9637\n",
            "Epoch 150/1000\n",
            "61/61 [==============================] - 0s 6ms/step - loss: 0.1169 - accuracy: 0.9694\n",
            "Epoch 151/1000\n",
            "61/61 [==============================] - 0s 7ms/step - loss: 0.1089 - accuracy: 0.9704\n",
            "Epoch 152/1000\n",
            "61/61 [==============================] - 0s 5ms/step - loss: 0.1152 - accuracy: 0.9626\n",
            "Epoch 153/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.1086 - accuracy: 0.9694\n",
            "Epoch 154/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.1089 - accuracy: 0.9678\n",
            "Epoch 155/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.1132 - accuracy: 0.9657\n",
            "Epoch 156/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.1025 - accuracy: 0.9704\n",
            "Epoch 157/1000\n",
            "61/61 [==============================] - 0s 6ms/step - loss: 0.1055 - accuracy: 0.9689\n",
            "Epoch 158/1000\n",
            "61/61 [==============================] - 0s 5ms/step - loss: 0.1093 - accuracy: 0.9709\n",
            "Epoch 159/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.1039 - accuracy: 0.9689\n",
            "Epoch 160/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.1133 - accuracy: 0.9652\n",
            "Epoch 161/1000\n",
            "61/61 [==============================] - 0s 5ms/step - loss: 0.1056 - accuracy: 0.9735\n",
            "Epoch 162/1000\n",
            "61/61 [==============================] - 0s 6ms/step - loss: 0.0992 - accuracy: 0.9766\n",
            "Epoch 163/1000\n",
            "61/61 [==============================] - 0s 5ms/step - loss: 0.0957 - accuracy: 0.9766\n",
            "Epoch 164/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.1067 - accuracy: 0.9689\n",
            "Epoch 165/1000\n",
            "61/61 [==============================] - 0s 7ms/step - loss: 0.1104 - accuracy: 0.9683\n",
            "Epoch 166/1000\n",
            "61/61 [==============================] - 0s 7ms/step - loss: 0.1144 - accuracy: 0.9642\n",
            "Epoch 167/1000\n",
            "61/61 [==============================] - 0s 5ms/step - loss: 0.0986 - accuracy: 0.9730\n",
            "Epoch 168/1000\n",
            "61/61 [==============================] - 0s 6ms/step - loss: 0.1031 - accuracy: 0.9725\n",
            "Epoch 169/1000\n",
            "61/61 [==============================] - 0s 6ms/step - loss: 0.0902 - accuracy: 0.9766\n",
            "Epoch 170/1000\n",
            "61/61 [==============================] - 0s 6ms/step - loss: 0.0929 - accuracy: 0.9709\n",
            "Epoch 171/1000\n",
            "61/61 [==============================] - 0s 6ms/step - loss: 0.0845 - accuracy: 0.9772\n",
            "Epoch 172/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0922 - accuracy: 0.9792\n",
            "Epoch 173/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0826 - accuracy: 0.9798\n",
            "Epoch 174/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0898 - accuracy: 0.9761\n",
            "Epoch 175/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.1024 - accuracy: 0.9663\n",
            "Epoch 176/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0955 - accuracy: 0.9720\n",
            "Epoch 177/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0872 - accuracy: 0.9766\n",
            "Epoch 178/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0848 - accuracy: 0.9756\n",
            "Epoch 179/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0840 - accuracy: 0.9798\n",
            "Epoch 180/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0887 - accuracy: 0.9746\n",
            "Epoch 181/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0925 - accuracy: 0.9720\n",
            "Epoch 182/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0897 - accuracy: 0.9735\n",
            "Epoch 183/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0845 - accuracy: 0.9766\n",
            "Epoch 184/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0947 - accuracy: 0.9746\n",
            "Epoch 185/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0800 - accuracy: 0.9782\n",
            "Epoch 186/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0892 - accuracy: 0.9746\n",
            "Epoch 187/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0868 - accuracy: 0.9798\n",
            "Epoch 188/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0779 - accuracy: 0.9798\n",
            "Epoch 189/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0756 - accuracy: 0.9813\n",
            "Epoch 190/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0788 - accuracy: 0.9798\n",
            "Epoch 191/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0749 - accuracy: 0.9818\n",
            "Epoch 192/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0721 - accuracy: 0.9813\n",
            "Epoch 193/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0721 - accuracy: 0.9844\n",
            "Epoch 194/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0820 - accuracy: 0.9741\n",
            "Epoch 195/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0830 - accuracy: 0.9803\n",
            "Epoch 196/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0760 - accuracy: 0.9813\n",
            "Epoch 197/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0892 - accuracy: 0.9766\n",
            "Epoch 198/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0840 - accuracy: 0.9715\n",
            "Epoch 199/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0765 - accuracy: 0.9782\n",
            "Epoch 200/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0759 - accuracy: 0.9803\n",
            "Epoch 201/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0734 - accuracy: 0.9818\n",
            "Epoch 202/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.1001 - accuracy: 0.9751\n",
            "Epoch 203/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0758 - accuracy: 0.9818\n",
            "Epoch 204/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0908 - accuracy: 0.9766\n",
            "Epoch 205/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0951 - accuracy: 0.9730\n",
            "Epoch 206/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0695 - accuracy: 0.9839\n",
            "Epoch 207/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0646 - accuracy: 0.9834\n",
            "Epoch 208/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0736 - accuracy: 0.9839\n",
            "Epoch 209/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0632 - accuracy: 0.9829\n",
            "Epoch 210/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0711 - accuracy: 0.9818\n",
            "Epoch 211/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0681 - accuracy: 0.9829\n",
            "Epoch 212/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0707 - accuracy: 0.9803\n",
            "Epoch 213/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.9813\n",
            "Epoch 214/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0993 - accuracy: 0.9709\n",
            "Epoch 215/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0767 - accuracy: 0.9766\n",
            "Epoch 216/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0645 - accuracy: 0.9834\n",
            "Epoch 217/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.9834\n",
            "Epoch 218/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0760 - accuracy: 0.9792\n",
            "Epoch 219/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0568 - accuracy: 0.9865\n",
            "Epoch 220/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0562 - accuracy: 0.9865\n",
            "Epoch 221/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0848 - accuracy: 0.9746\n",
            "Epoch 222/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0710 - accuracy: 0.9824\n",
            "Epoch 223/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0595 - accuracy: 0.9875\n",
            "Epoch 224/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0614 - accuracy: 0.9855\n",
            "Epoch 225/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0652 - accuracy: 0.9829\n",
            "Epoch 226/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0607 - accuracy: 0.9829\n",
            "Epoch 227/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0561 - accuracy: 0.9886\n",
            "Epoch 228/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0581 - accuracy: 0.9860\n",
            "Epoch 229/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0605 - accuracy: 0.9855\n",
            "Epoch 230/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0560 - accuracy: 0.9886\n",
            "Epoch 231/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0576 - accuracy: 0.9860\n",
            "Epoch 232/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0624 - accuracy: 0.9834\n",
            "Epoch 233/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0759 - accuracy: 0.9772\n",
            "Epoch 234/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0596 - accuracy: 0.9834\n",
            "Epoch 235/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0502 - accuracy: 0.9875\n",
            "Epoch 236/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0551 - accuracy: 0.9886\n",
            "Epoch 237/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0616 - accuracy: 0.9855\n",
            "Epoch 238/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0559 - accuracy: 0.9855\n",
            "Epoch 239/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0567 - accuracy: 0.9875\n",
            "Epoch 240/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0582 - accuracy: 0.9850\n",
            "Epoch 241/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0487 - accuracy: 0.9855\n",
            "Epoch 242/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0653 - accuracy: 0.9808\n",
            "Epoch 243/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0715 - accuracy: 0.9777\n",
            "Epoch 244/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0580 - accuracy: 0.9860\n",
            "Epoch 245/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0575 - accuracy: 0.9870\n",
            "Epoch 246/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0543 - accuracy: 0.9870\n",
            "Epoch 247/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0563 - accuracy: 0.9865\n",
            "Epoch 248/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0554 - accuracy: 0.9860\n",
            "Epoch 249/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0563 - accuracy: 0.9855\n",
            "Epoch 250/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0494 - accuracy: 0.9881\n",
            "Epoch 251/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0636 - accuracy: 0.9860\n",
            "Epoch 252/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0803 - accuracy: 0.9798\n",
            "Epoch 253/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0742 - accuracy: 0.9782\n",
            "Epoch 254/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.1063 - accuracy: 0.9683\n",
            "Epoch 255/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0756 - accuracy: 0.9792\n",
            "Epoch 256/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0597 - accuracy: 0.9824\n",
            "Epoch 257/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0598 - accuracy: 0.9870\n",
            "Epoch 258/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0476 - accuracy: 0.9896\n",
            "Epoch 259/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0529 - accuracy: 0.9870\n",
            "Epoch 260/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0516 - accuracy: 0.9896\n",
            "Epoch 261/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0498 - accuracy: 0.9907\n",
            "Epoch 262/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0509 - accuracy: 0.9881\n",
            "Epoch 263/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0427 - accuracy: 0.9886\n",
            "Epoch 264/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0412 - accuracy: 0.9917\n",
            "Epoch 265/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0463 - accuracy: 0.9912\n",
            "Epoch 266/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0547 - accuracy: 0.9875\n",
            "Epoch 267/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0564 - accuracy: 0.9870\n",
            "Epoch 268/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0388 - accuracy: 0.9901\n",
            "Epoch 269/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0547 - accuracy: 0.9870\n",
            "Epoch 270/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0508 - accuracy: 0.9881\n",
            "Epoch 271/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0515 - accuracy: 0.9896\n",
            "Epoch 272/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0525 - accuracy: 0.9865\n",
            "Epoch 273/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0511 - accuracy: 0.9886\n",
            "Epoch 274/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0490 - accuracy: 0.9855\n",
            "Epoch 275/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0485 - accuracy: 0.9901\n",
            "Epoch 276/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0469 - accuracy: 0.9891\n",
            "Epoch 277/1000\n",
            "61/61 [==============================] - 0s 5ms/step - loss: 0.0476 - accuracy: 0.9886\n",
            "Epoch 278/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0465 - accuracy: 0.9881\n",
            "Epoch 279/1000\n",
            "61/61 [==============================] - 0s 5ms/step - loss: 0.0500 - accuracy: 0.9901\n",
            "Epoch 280/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0495 - accuracy: 0.9870\n",
            "Epoch 281/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0506 - accuracy: 0.9891\n",
            "Epoch 282/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0418 - accuracy: 0.9896\n",
            "Epoch 283/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0490 - accuracy: 0.9896\n",
            "Epoch 284/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0455 - accuracy: 0.9896\n",
            "Epoch 285/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0442 - accuracy: 0.9912\n",
            "Epoch 286/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0473 - accuracy: 0.9896\n",
            "Epoch 287/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0455 - accuracy: 0.9891\n",
            "Epoch 288/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0497 - accuracy: 0.9860\n",
            "Epoch 289/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.1264 - accuracy: 0.9611\n",
            "Epoch 290/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0811 - accuracy: 0.9735\n",
            "Epoch 291/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0747 - accuracy: 0.9772\n",
            "Epoch 292/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0586 - accuracy: 0.9839\n",
            "Epoch 293/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0429 - accuracy: 0.9896\n",
            "Epoch 294/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0418 - accuracy: 0.9891\n",
            "Epoch 295/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0414 - accuracy: 0.9912\n",
            "Epoch 296/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0455 - accuracy: 0.9891\n",
            "Epoch 297/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0396 - accuracy: 0.9917\n",
            "Epoch 298/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0448 - accuracy: 0.9896\n",
            "Epoch 299/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0389 - accuracy: 0.9896\n",
            "Epoch 300/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0385 - accuracy: 0.9896\n",
            "Epoch 301/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0512 - accuracy: 0.9865\n",
            "Epoch 302/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0369 - accuracy: 0.9896\n",
            "Epoch 303/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0466 - accuracy: 0.9917\n",
            "Epoch 304/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0423 - accuracy: 0.9907\n",
            "Epoch 305/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0366 - accuracy: 0.9891\n",
            "Epoch 306/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0356 - accuracy: 0.9917\n",
            "Epoch 307/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0397 - accuracy: 0.9912\n",
            "Epoch 308/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0488 - accuracy: 0.9896\n",
            "Epoch 309/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0446 - accuracy: 0.9912\n",
            "Epoch 310/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0368 - accuracy: 0.9917\n",
            "Epoch 311/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0389 - accuracy: 0.9907\n",
            "Epoch 312/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0403 - accuracy: 0.9891\n",
            "Epoch 313/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0435 - accuracy: 0.9875\n",
            "Epoch 314/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0434 - accuracy: 0.9891\n",
            "Epoch 315/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0390 - accuracy: 0.9917\n",
            "Epoch 316/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0362 - accuracy: 0.9901\n",
            "Epoch 317/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0395 - accuracy: 0.9907\n",
            "Epoch 318/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0424 - accuracy: 0.9917\n",
            "Epoch 319/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0388 - accuracy: 0.9922\n",
            "Epoch 320/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0425 - accuracy: 0.9896\n",
            "Epoch 321/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0475 - accuracy: 0.9901\n",
            "Epoch 322/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0456 - accuracy: 0.9896\n",
            "Epoch 323/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0348 - accuracy: 0.9922\n",
            "Epoch 324/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0392 - accuracy: 0.9907\n",
            "Epoch 325/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0478 - accuracy: 0.9855\n",
            "Epoch 326/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0649 - accuracy: 0.9808\n",
            "Epoch 327/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0605 - accuracy: 0.9865\n",
            "Epoch 328/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.1399 - accuracy: 0.9611\n",
            "Epoch 329/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0722 - accuracy: 0.9766\n",
            "Epoch 330/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0660 - accuracy: 0.9766\n",
            "Epoch 331/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0615 - accuracy: 0.9839\n",
            "Epoch 332/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0427 - accuracy: 0.9886\n",
            "Epoch 333/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0412 - accuracy: 0.9912\n",
            "Epoch 334/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0354 - accuracy: 0.9912\n",
            "Epoch 335/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0434 - accuracy: 0.9891\n",
            "Epoch 336/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0377 - accuracy: 0.9896\n",
            "Epoch 337/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0315 - accuracy: 0.9922\n",
            "Epoch 338/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0357 - accuracy: 0.9907\n",
            "Epoch 339/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0379 - accuracy: 0.9907\n",
            "Epoch 340/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0390 - accuracy: 0.9891\n",
            "Epoch 341/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0387 - accuracy: 0.9917\n",
            "Epoch 342/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0375 - accuracy: 0.9901\n",
            "Epoch 343/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0537 - accuracy: 0.9844\n",
            "Epoch 344/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0393 - accuracy: 0.9896\n",
            "Epoch 345/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0405 - accuracy: 0.9907\n",
            "Epoch 346/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0590 - accuracy: 0.9850\n",
            "Epoch 347/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0746 - accuracy: 0.9860\n",
            "Epoch 348/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0586 - accuracy: 0.9834\n",
            "Epoch 349/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0826 - accuracy: 0.9787\n",
            "Epoch 350/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0562 - accuracy: 0.9855\n",
            "Epoch 351/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0539 - accuracy: 0.9818\n",
            "Epoch 352/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0433 - accuracy: 0.9891\n",
            "Epoch 353/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0348 - accuracy: 0.9912\n",
            "Epoch 354/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0354 - accuracy: 0.9917\n",
            "Epoch 355/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0365 - accuracy: 0.9917\n",
            "Epoch 356/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0331 - accuracy: 0.9907\n",
            "Epoch 357/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0366 - accuracy: 0.9907\n",
            "Epoch 358/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0350 - accuracy: 0.9922\n",
            "Epoch 359/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0329 - accuracy: 0.9912\n",
            "Epoch 360/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0339 - accuracy: 0.9912\n",
            "Epoch 361/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0431 - accuracy: 0.9886\n",
            "Epoch 362/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0391 - accuracy: 0.9912\n",
            "Epoch 363/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0312 - accuracy: 0.9917\n",
            "Epoch 364/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0296 - accuracy: 0.9938\n",
            "Epoch 365/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0408 - accuracy: 0.9907\n",
            "Epoch 366/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0485 - accuracy: 0.9896\n",
            "Epoch 367/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0417 - accuracy: 0.9896\n",
            "Epoch 368/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0401 - accuracy: 0.9886\n",
            "Epoch 369/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0300 - accuracy: 0.9922\n",
            "Epoch 370/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0408 - accuracy: 0.9917\n",
            "Epoch 371/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0338 - accuracy: 0.9907\n",
            "Epoch 372/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0429 - accuracy: 0.9865\n",
            "Epoch 373/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0352 - accuracy: 0.9927\n",
            "Epoch 374/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0420 - accuracy: 0.9901\n",
            "Epoch 375/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0336 - accuracy: 0.9922\n",
            "Epoch 376/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0402 - accuracy: 0.9912\n",
            "Epoch 377/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0431 - accuracy: 0.9907\n",
            "Epoch 378/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0387 - accuracy: 0.9917\n",
            "Epoch 379/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0388 - accuracy: 0.9922\n",
            "Epoch 380/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0297 - accuracy: 0.9943\n",
            "Epoch 381/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0377 - accuracy: 0.9922\n",
            "Epoch 382/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0486 - accuracy: 0.9860\n",
            "Epoch 383/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0410 - accuracy: 0.9912\n",
            "Epoch 384/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0386 - accuracy: 0.9901\n",
            "Epoch 385/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0331 - accuracy: 0.9917\n",
            "Epoch 386/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0522 - accuracy: 0.9865\n",
            "Epoch 387/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0341 - accuracy: 0.9907\n",
            "Epoch 388/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0421 - accuracy: 0.9886\n",
            "Epoch 389/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0567 - accuracy: 0.9844\n",
            "Epoch 390/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.1240 - accuracy: 0.9678\n",
            "Epoch 391/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.1384 - accuracy: 0.9595\n",
            "Epoch 392/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0906 - accuracy: 0.9704\n",
            "Epoch 393/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0595 - accuracy: 0.9803\n",
            "Epoch 394/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0465 - accuracy: 0.9901\n",
            "Epoch 395/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0547 - accuracy: 0.9844\n",
            "Epoch 396/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0428 - accuracy: 0.9881\n",
            "Epoch 397/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0340 - accuracy: 0.9912\n",
            "Epoch 398/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0302 - accuracy: 0.9938\n",
            "Epoch 399/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0309 - accuracy: 0.9922\n",
            "Epoch 400/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0362 - accuracy: 0.9907\n",
            "Epoch 401/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0303 - accuracy: 0.9927\n",
            "Epoch 402/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0298 - accuracy: 0.9927\n",
            "Epoch 403/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0325 - accuracy: 0.9922\n",
            "Epoch 404/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0307 - accuracy: 0.9922\n",
            "Epoch 405/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0460 - accuracy: 0.9901\n",
            "Epoch 406/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0369 - accuracy: 0.9933\n",
            "Epoch 407/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0307 - accuracy: 0.9927\n",
            "Epoch 408/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0347 - accuracy: 0.9917\n",
            "Epoch 409/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0338 - accuracy: 0.9907\n",
            "Epoch 410/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0288 - accuracy: 0.9922\n",
            "Epoch 411/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0341 - accuracy: 0.9907\n",
            "Epoch 412/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0456 - accuracy: 0.9875\n",
            "Epoch 413/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0334 - accuracy: 0.9938\n",
            "Epoch 414/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0317 - accuracy: 0.9922\n",
            "Epoch 415/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0325 - accuracy: 0.9927\n",
            "Epoch 416/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0328 - accuracy: 0.9912\n",
            "Epoch 417/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0341 - accuracy: 0.9917\n",
            "Epoch 418/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0328 - accuracy: 0.9922\n",
            "Epoch 419/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0310 - accuracy: 0.9927\n",
            "Epoch 420/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0305 - accuracy: 0.9912\n",
            "Epoch 421/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0253 - accuracy: 0.9943\n",
            "Epoch 422/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0530 - accuracy: 0.9855\n",
            "Epoch 423/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0445 - accuracy: 0.9896\n",
            "Epoch 424/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0427 - accuracy: 0.9891\n",
            "Epoch 425/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0455 - accuracy: 0.9901\n",
            "Epoch 426/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0388 - accuracy: 0.9907\n",
            "Epoch 427/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0444 - accuracy: 0.9907\n",
            "Epoch 428/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0532 - accuracy: 0.9824\n",
            "Epoch 429/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0420 - accuracy: 0.9907\n",
            "Epoch 430/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0591 - accuracy: 0.9824\n",
            "Epoch 431/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0540 - accuracy: 0.9824\n",
            "Epoch 432/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0356 - accuracy: 0.9881\n",
            "Epoch 433/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0457 - accuracy: 0.9886\n",
            "Epoch 434/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0310 - accuracy: 0.9922\n",
            "Epoch 435/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0259 - accuracy: 0.9927\n",
            "Epoch 436/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0345 - accuracy: 0.9901\n",
            "Epoch 437/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0276 - accuracy: 0.9938\n",
            "Epoch 438/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0616 - accuracy: 0.9886\n",
            "Epoch 439/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0296 - accuracy: 0.9938\n",
            "Epoch 440/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0307 - accuracy: 0.9938\n",
            "Epoch 441/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0336 - accuracy: 0.9917\n",
            "Epoch 442/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0238 - accuracy: 0.9938\n",
            "Epoch 443/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0368 - accuracy: 0.9922\n",
            "Epoch 444/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0258 - accuracy: 0.9943\n",
            "Epoch 445/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 0.9907\n",
            "Epoch 446/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0339 - accuracy: 0.9917\n",
            "Epoch 447/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0284 - accuracy: 0.9938\n",
            "Epoch 448/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0401 - accuracy: 0.9907\n",
            "Epoch 449/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0365 - accuracy: 0.9907\n",
            "Epoch 450/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0373 - accuracy: 0.9901\n",
            "Epoch 451/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0307 - accuracy: 0.9917\n",
            "Epoch 452/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0264 - accuracy: 0.9933\n",
            "Epoch 453/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0351 - accuracy: 0.9922\n",
            "Epoch 454/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0290 - accuracy: 0.9943\n",
            "Epoch 455/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0293 - accuracy: 0.9917\n",
            "Epoch 456/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0266 - accuracy: 0.9933\n",
            "Epoch 457/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0315 - accuracy: 0.9922\n",
            "Epoch 458/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0422 - accuracy: 0.9875\n",
            "Epoch 459/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0493 - accuracy: 0.9865\n",
            "Epoch 460/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0457 - accuracy: 0.9881\n",
            "Epoch 461/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0504 - accuracy: 0.9870\n",
            "Epoch 462/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0488 - accuracy: 0.9829\n",
            "Epoch 463/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0510 - accuracy: 0.9865\n",
            "Epoch 464/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0494 - accuracy: 0.9860\n",
            "Epoch 465/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0566 - accuracy: 0.9860\n",
            "Epoch 466/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0538 - accuracy: 0.9860\n",
            "Epoch 467/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.1005 - accuracy: 0.9694\n",
            "Epoch 468/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0474 - accuracy: 0.9881\n",
            "Epoch 469/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0333 - accuracy: 0.9907\n",
            "Epoch 470/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0295 - accuracy: 0.9917\n",
            "Epoch 471/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0322 - accuracy: 0.9933\n",
            "Epoch 472/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0215 - accuracy: 0.9938\n",
            "Epoch 473/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0281 - accuracy: 0.9933\n",
            "Epoch 474/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0276 - accuracy: 0.9917\n",
            "Epoch 475/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0301 - accuracy: 0.9917\n",
            "Epoch 476/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0327 - accuracy: 0.9917\n",
            "Epoch 477/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0245 - accuracy: 0.9933\n",
            "Epoch 478/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0254 - accuracy: 0.9933\n",
            "Epoch 479/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0223 - accuracy: 0.9938\n",
            "Epoch 480/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0297 - accuracy: 0.9933\n",
            "Epoch 481/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0299 - accuracy: 0.9912\n",
            "Epoch 482/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0284 - accuracy: 0.9933\n",
            "Epoch 483/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0244 - accuracy: 0.9933\n",
            "Epoch 484/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0299 - accuracy: 0.9933\n",
            "Epoch 485/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0292 - accuracy: 0.9922\n",
            "Epoch 486/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0317 - accuracy: 0.9938\n",
            "Epoch 487/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0316 - accuracy: 0.9933\n",
            "Epoch 488/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0303 - accuracy: 0.9938\n",
            "Epoch 489/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0462 - accuracy: 0.9896\n",
            "Epoch 490/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0260 - accuracy: 0.9927\n",
            "Epoch 491/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0294 - accuracy: 0.9933\n",
            "Epoch 492/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0498 - accuracy: 0.9850\n",
            "Epoch 493/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0524 - accuracy: 0.9850\n",
            "Epoch 494/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0640 - accuracy: 0.9792\n",
            "Epoch 495/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0640 - accuracy: 0.9787\n",
            "Epoch 496/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.9792\n",
            "Epoch 497/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0415 - accuracy: 0.9896\n",
            "Epoch 498/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0376 - accuracy: 0.9907\n",
            "Epoch 499/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0336 - accuracy: 0.9901\n",
            "Epoch 500/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0298 - accuracy: 0.9907\n",
            "Epoch 501/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0336 - accuracy: 0.9917\n",
            "Epoch 502/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0288 - accuracy: 0.9943\n",
            "Epoch 503/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0255 - accuracy: 0.9938\n",
            "Epoch 504/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0280 - accuracy: 0.9927\n",
            "Epoch 505/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0337 - accuracy: 0.9917\n",
            "Epoch 506/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0244 - accuracy: 0.9933\n",
            "Epoch 507/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0274 - accuracy: 0.9933\n",
            "Epoch 508/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0360 - accuracy: 0.9901\n",
            "Epoch 509/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0558 - accuracy: 0.9850\n",
            "Epoch 510/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0299 - accuracy: 0.9927\n",
            "Epoch 511/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0319 - accuracy: 0.9927\n",
            "Epoch 512/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0307 - accuracy: 0.9938\n",
            "Epoch 513/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0256 - accuracy: 0.9927\n",
            "Epoch 514/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0207 - accuracy: 0.9922\n",
            "Epoch 515/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0284 - accuracy: 0.9922\n",
            "Epoch 516/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0296 - accuracy: 0.9933\n",
            "Epoch 517/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0346 - accuracy: 0.9927\n",
            "Epoch 518/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0297 - accuracy: 0.9922\n",
            "Epoch 519/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0325 - accuracy: 0.9922\n",
            "Epoch 520/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0247 - accuracy: 0.9927\n",
            "Epoch 521/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0316 - accuracy: 0.9917\n",
            "Epoch 522/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0527 - accuracy: 0.9865\n",
            "Epoch 523/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0340 - accuracy: 0.9901\n",
            "Epoch 524/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0272 - accuracy: 0.9927\n",
            "Epoch 525/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0309 - accuracy: 0.9922\n",
            "Epoch 526/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0253 - accuracy: 0.9917\n",
            "Epoch 527/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0334 - accuracy: 0.9917\n",
            "Epoch 528/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0356 - accuracy: 0.9891\n",
            "Epoch 529/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0427 - accuracy: 0.9891\n",
            "Epoch 530/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0862 - accuracy: 0.9792\n",
            "Epoch 531/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0925 - accuracy: 0.9746\n",
            "Epoch 532/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.2014 - accuracy: 0.9533\n",
            "Epoch 533/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0739 - accuracy: 0.9725\n",
            "Epoch 534/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0395 - accuracy: 0.9881\n",
            "Epoch 535/1000\n",
            "61/61 [==============================] - 0s 5ms/step - loss: 0.0379 - accuracy: 0.9907\n",
            "Epoch 536/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0280 - accuracy: 0.9922\n",
            "Epoch 537/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0452 - accuracy: 0.9907\n",
            "Epoch 538/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0251 - accuracy: 0.9938\n",
            "Epoch 539/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0221 - accuracy: 0.9938\n",
            "Epoch 540/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0236 - accuracy: 0.9922\n",
            "Epoch 541/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0201 - accuracy: 0.9933\n",
            "Epoch 542/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0345 - accuracy: 0.9933\n",
            "Epoch 543/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0256 - accuracy: 0.9938\n",
            "Epoch 544/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0185 - accuracy: 0.9938\n",
            "Epoch 545/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0236 - accuracy: 0.9933\n",
            "Epoch 546/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0244 - accuracy: 0.9943\n",
            "Epoch 547/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0320 - accuracy: 0.9933\n",
            "Epoch 548/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0285 - accuracy: 0.9927\n",
            "Epoch 549/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0256 - accuracy: 0.9922\n",
            "Epoch 550/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0255 - accuracy: 0.9933\n",
            "Epoch 551/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0286 - accuracy: 0.9922\n",
            "Epoch 552/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0253 - accuracy: 0.9948\n",
            "Epoch 553/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0363 - accuracy: 0.9917\n",
            "Epoch 554/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0270 - accuracy: 0.9927\n",
            "Epoch 555/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0295 - accuracy: 0.9927\n",
            "Epoch 556/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0318 - accuracy: 0.9917\n",
            "Epoch 557/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0253 - accuracy: 0.9922\n",
            "Epoch 558/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0273 - accuracy: 0.9917\n",
            "Epoch 559/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0240 - accuracy: 0.9927\n",
            "Epoch 560/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0248 - accuracy: 0.9933\n",
            "Epoch 561/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0231 - accuracy: 0.9948\n",
            "Epoch 562/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0530 - accuracy: 0.9844\n",
            "Epoch 563/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0586 - accuracy: 0.9813\n",
            "Epoch 564/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0347 - accuracy: 0.9891\n",
            "Epoch 565/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 0.9901\n",
            "Epoch 566/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0319 - accuracy: 0.9922\n",
            "Epoch 567/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0413 - accuracy: 0.9881\n",
            "Epoch 568/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0367 - accuracy: 0.9912\n",
            "Epoch 569/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0266 - accuracy: 0.9943\n",
            "Epoch 570/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0344 - accuracy: 0.9922\n",
            "Epoch 571/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0266 - accuracy: 0.9943\n",
            "Epoch 572/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0247 - accuracy: 0.9938\n",
            "Epoch 573/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0298 - accuracy: 0.9922\n",
            "Epoch 574/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0609 - accuracy: 0.9808\n",
            "Epoch 575/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0286 - accuracy: 0.9938\n",
            "Epoch 576/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0298 - accuracy: 0.9912\n",
            "Epoch 577/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0251 - accuracy: 0.9922\n",
            "Epoch 578/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0302 - accuracy: 0.9938\n",
            "Epoch 579/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0216 - accuracy: 0.9927\n",
            "Epoch 580/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0257 - accuracy: 0.9927\n",
            "Epoch 581/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0278 - accuracy: 0.9938\n",
            "Epoch 582/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0318 - accuracy: 0.9943\n",
            "Epoch 583/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0245 - accuracy: 0.9927\n",
            "Epoch 584/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0253 - accuracy: 0.9933\n",
            "Epoch 585/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0369 - accuracy: 0.9907\n",
            "Epoch 586/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0296 - accuracy: 0.9927\n",
            "Epoch 587/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0469 - accuracy: 0.9881\n",
            "Epoch 588/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0420 - accuracy: 0.9881\n",
            "Epoch 589/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0424 - accuracy: 0.9865\n",
            "Epoch 590/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0447 - accuracy: 0.9865\n",
            "Epoch 591/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0403 - accuracy: 0.9875\n",
            "Epoch 592/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0349 - accuracy: 0.9933\n",
            "Epoch 593/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0279 - accuracy: 0.9922\n",
            "Epoch 594/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0318 - accuracy: 0.9927\n",
            "Epoch 595/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0690 - accuracy: 0.9798\n",
            "Epoch 596/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.1056 - accuracy: 0.9683\n",
            "Epoch 597/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0463 - accuracy: 0.9824\n",
            "Epoch 598/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0328 - accuracy: 0.9933\n",
            "Epoch 599/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0272 - accuracy: 0.9943\n",
            "Epoch 600/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0214 - accuracy: 0.9933\n",
            "Epoch 601/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0267 - accuracy: 0.9933\n",
            "Epoch 602/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0357 - accuracy: 0.9922\n",
            "Epoch 603/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0229 - accuracy: 0.9948\n",
            "Epoch 604/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0290 - accuracy: 0.9943\n",
            "Epoch 605/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0315 - accuracy: 0.9912\n",
            "Epoch 606/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0291 - accuracy: 0.9933\n",
            "Epoch 607/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0268 - accuracy: 0.9933\n",
            "Epoch 608/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0369 - accuracy: 0.9922\n",
            "Epoch 609/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0255 - accuracy: 0.9922\n",
            "Epoch 610/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0346 - accuracy: 0.9922\n",
            "Epoch 611/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0299 - accuracy: 0.9938\n",
            "Epoch 612/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0314 - accuracy: 0.9938\n",
            "Epoch 613/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0289 - accuracy: 0.9917\n",
            "Epoch 614/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0233 - accuracy: 0.9922\n",
            "Epoch 615/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0250 - accuracy: 0.9943\n",
            "Epoch 616/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0357 - accuracy: 0.9907\n",
            "Epoch 617/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0247 - accuracy: 0.9907\n",
            "Epoch 618/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0300 - accuracy: 0.9938\n",
            "Epoch 619/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0260 - accuracy: 0.9938\n",
            "Epoch 620/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0270 - accuracy: 0.9938\n",
            "Epoch 621/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0339 - accuracy: 0.9927\n",
            "Epoch 622/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0282 - accuracy: 0.9907\n",
            "Epoch 623/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0325 - accuracy: 0.9933\n",
            "Epoch 624/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0362 - accuracy: 0.9917\n",
            "Epoch 625/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0297 - accuracy: 0.9922\n",
            "Epoch 626/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0263 - accuracy: 0.9933\n",
            "Epoch 627/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0286 - accuracy: 0.9933\n",
            "Epoch 628/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0419 - accuracy: 0.9881\n",
            "Epoch 629/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0367 - accuracy: 0.9881\n",
            "Epoch 630/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0995 - accuracy: 0.9704\n",
            "Epoch 631/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0927 - accuracy: 0.9678\n",
            "Epoch 632/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0367 - accuracy: 0.9907\n",
            "Epoch 633/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0295 - accuracy: 0.9933\n",
            "Epoch 634/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0232 - accuracy: 0.9927\n",
            "Epoch 635/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0233 - accuracy: 0.9943\n",
            "Epoch 636/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0272 - accuracy: 0.9938\n",
            "Epoch 637/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0313 - accuracy: 0.9933\n",
            "Epoch 638/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0234 - accuracy: 0.9943\n",
            "Epoch 639/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0292 - accuracy: 0.9917\n",
            "Epoch 640/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0298 - accuracy: 0.9933\n",
            "Epoch 641/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0245 - accuracy: 0.9943\n",
            "Epoch 642/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0287 - accuracy: 0.9933\n",
            "Epoch 643/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0280 - accuracy: 0.9943\n",
            "Epoch 644/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0271 - accuracy: 0.9933\n",
            "Epoch 645/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0308 - accuracy: 0.9922\n",
            "Epoch 646/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0290 - accuracy: 0.9933\n",
            "Epoch 647/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0220 - accuracy: 0.9943\n",
            "Epoch 648/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0231 - accuracy: 0.9943\n",
            "Epoch 649/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0284 - accuracy: 0.9927\n",
            "Epoch 650/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0278 - accuracy: 0.9938\n",
            "Epoch 651/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0255 - accuracy: 0.9938\n",
            "Epoch 652/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0283 - accuracy: 0.9933\n",
            "Epoch 653/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0262 - accuracy: 0.9933\n",
            "Epoch 654/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0262 - accuracy: 0.9943\n",
            "Epoch 655/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0378 - accuracy: 0.9922\n",
            "Epoch 656/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0345 - accuracy: 0.9933\n",
            "Epoch 657/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0261 - accuracy: 0.9938\n",
            "Epoch 658/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0340 - accuracy: 0.9912\n",
            "Epoch 659/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0346 - accuracy: 0.9917\n",
            "Epoch 660/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0351 - accuracy: 0.9938\n",
            "Epoch 661/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0363 - accuracy: 0.9927\n",
            "Epoch 662/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0294 - accuracy: 0.9933\n",
            "Epoch 663/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0298 - accuracy: 0.9912\n",
            "Epoch 664/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0375 - accuracy: 0.9907\n",
            "Epoch 665/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0313 - accuracy: 0.9912\n",
            "Epoch 666/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0250 - accuracy: 0.9933\n",
            "Epoch 667/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0232 - accuracy: 0.9938\n",
            "Epoch 668/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0205 - accuracy: 0.9927\n",
            "Epoch 669/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0344 - accuracy: 0.9917\n",
            "Epoch 670/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0304 - accuracy: 0.9933\n",
            "Epoch 671/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0253 - accuracy: 0.9927\n",
            "Epoch 672/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0258 - accuracy: 0.9933\n",
            "Epoch 673/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0233 - accuracy: 0.9938\n",
            "Epoch 674/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0379 - accuracy: 0.9922\n",
            "Epoch 675/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0312 - accuracy: 0.9933\n",
            "Epoch 676/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0291 - accuracy: 0.9922\n",
            "Epoch 677/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0315 - accuracy: 0.9912\n",
            "Epoch 678/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0222 - accuracy: 0.9948\n",
            "Epoch 679/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0256 - accuracy: 0.9933\n",
            "Epoch 680/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0844 - accuracy: 0.9772\n",
            "Epoch 681/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.1273 - accuracy: 0.9663\n",
            "Epoch 682/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0967 - accuracy: 0.9725\n",
            "Epoch 683/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0626 - accuracy: 0.9818\n",
            "Epoch 684/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0364 - accuracy: 0.9896\n",
            "Epoch 685/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0320 - accuracy: 0.9901\n",
            "Epoch 686/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0253 - accuracy: 0.9933\n",
            "Epoch 687/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0228 - accuracy: 0.9922\n",
            "Epoch 688/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0390 - accuracy: 0.9907\n",
            "Epoch 689/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0238 - accuracy: 0.9922\n",
            "Epoch 690/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0272 - accuracy: 0.9922\n",
            "Epoch 691/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0244 - accuracy: 0.9938\n",
            "Epoch 692/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0236 - accuracy: 0.9933\n",
            "Epoch 693/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0221 - accuracy: 0.9933\n",
            "Epoch 694/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0199 - accuracy: 0.9953\n",
            "Epoch 695/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0265 - accuracy: 0.9927\n",
            "Epoch 696/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0249 - accuracy: 0.9938\n",
            "Epoch 697/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0265 - accuracy: 0.9943\n",
            "Epoch 698/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0233 - accuracy: 0.9933\n",
            "Epoch 699/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0218 - accuracy: 0.9943\n",
            "Epoch 700/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0181 - accuracy: 0.9953\n",
            "Epoch 701/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0253 - accuracy: 0.9927\n",
            "Epoch 702/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0262 - accuracy: 0.9922\n",
            "Epoch 703/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0257 - accuracy: 0.9927\n",
            "Epoch 704/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0566 - accuracy: 0.9855\n",
            "Epoch 705/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0291 - accuracy: 0.9917\n",
            "Epoch 706/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0245 - accuracy: 0.9927\n",
            "Epoch 707/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0438 - accuracy: 0.9891\n",
            "Epoch 708/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0289 - accuracy: 0.9922\n",
            "Epoch 709/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0203 - accuracy: 0.9948\n",
            "Epoch 710/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0294 - accuracy: 0.9943\n",
            "Epoch 711/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0220 - accuracy: 0.9933\n",
            "Epoch 712/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0276 - accuracy: 0.9938\n",
            "Epoch 713/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0274 - accuracy: 0.9933\n",
            "Epoch 714/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0274 - accuracy: 0.9938\n",
            "Epoch 715/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0220 - accuracy: 0.9933\n",
            "Epoch 716/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0481 - accuracy: 0.9886\n",
            "Epoch 717/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0261 - accuracy: 0.9927\n",
            "Epoch 718/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0284 - accuracy: 0.9933\n",
            "Epoch 719/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0239 - accuracy: 0.9938\n",
            "Epoch 720/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0248 - accuracy: 0.9933\n",
            "Epoch 721/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0273 - accuracy: 0.9917\n",
            "Epoch 722/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0307 - accuracy: 0.9922\n",
            "Epoch 723/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0463 - accuracy: 0.9886\n",
            "Epoch 724/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0350 - accuracy: 0.9912\n",
            "Epoch 725/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0243 - accuracy: 0.9953\n",
            "Epoch 726/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0232 - accuracy: 0.9938\n",
            "Epoch 727/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0265 - accuracy: 0.9922\n",
            "Epoch 728/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0390 - accuracy: 0.9891\n",
            "Epoch 729/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.1008 - accuracy: 0.9746\n",
            "Epoch 730/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.1232 - accuracy: 0.9668\n",
            "Epoch 731/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0708 - accuracy: 0.9792\n",
            "Epoch 732/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0418 - accuracy: 0.9901\n",
            "Epoch 733/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0263 - accuracy: 0.9933\n",
            "Epoch 734/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0207 - accuracy: 0.9943\n",
            "Epoch 735/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0215 - accuracy: 0.9933\n",
            "Epoch 736/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0224 - accuracy: 0.9933\n",
            "Epoch 737/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0204 - accuracy: 0.9948\n",
            "Epoch 738/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0169 - accuracy: 0.9938\n",
            "Epoch 739/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0197 - accuracy: 0.9922\n",
            "Epoch 740/1000\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0164 - accuracy: 0.9953\n",
            "Epoch 741/1000\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.0180 - accuracy: 0.9953\n",
            "Epoch 742/1000\n",
            "61/61 [==============================] - 0s 7ms/step - loss: 0.0222 - accuracy: 0.9933\n",
            "Epoch 743/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0158 - accuracy: 0.9948\n",
            "Epoch 744/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0240 - accuracy: 0.9943\n",
            "Epoch 745/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0221 - accuracy: 0.9933\n",
            "Epoch 746/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0197 - accuracy: 0.9943\n",
            "Epoch 747/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0224 - accuracy: 0.9933\n",
            "Epoch 748/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0211 - accuracy: 0.9938\n",
            "Epoch 749/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0238 - accuracy: 0.9927\n",
            "Epoch 750/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0272 - accuracy: 0.9927\n",
            "Epoch 751/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0261 - accuracy: 0.9927\n",
            "Epoch 752/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0324 - accuracy: 0.9938\n",
            "Epoch 753/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0335 - accuracy: 0.9927\n",
            "Epoch 754/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0266 - accuracy: 0.9933\n",
            "Epoch 755/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0265 - accuracy: 0.9938\n",
            "Epoch 756/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0201 - accuracy: 0.9938\n",
            "Epoch 757/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0465 - accuracy: 0.9865\n",
            "Epoch 758/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0266 - accuracy: 0.9933\n",
            "Epoch 759/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0215 - accuracy: 0.9938\n",
            "Epoch 760/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0244 - accuracy: 0.9943\n",
            "Epoch 761/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0234 - accuracy: 0.9927\n",
            "Epoch 762/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0269 - accuracy: 0.9927\n",
            "Epoch 763/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0243 - accuracy: 0.9933\n",
            "Epoch 764/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0223 - accuracy: 0.9953\n",
            "Epoch 765/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0207 - accuracy: 0.9933\n",
            "Epoch 766/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0220 - accuracy: 0.9943\n",
            "Epoch 767/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0244 - accuracy: 0.9943\n",
            "Epoch 768/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0246 - accuracy: 0.9938\n",
            "Epoch 769/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0292 - accuracy: 0.9938\n",
            "Epoch 770/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0256 - accuracy: 0.9933\n",
            "Epoch 771/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0242 - accuracy: 0.9907\n",
            "Epoch 772/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0293 - accuracy: 0.9922\n",
            "Epoch 773/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0278 - accuracy: 0.9927\n",
            "Epoch 774/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0215 - accuracy: 0.9938\n",
            "Epoch 775/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0261 - accuracy: 0.9917\n",
            "Epoch 776/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0368 - accuracy: 0.9896\n",
            "Epoch 777/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0260 - accuracy: 0.9927\n",
            "Epoch 778/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0463 - accuracy: 0.9881\n",
            "Epoch 779/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.1126 - accuracy: 0.9772\n",
            "Epoch 780/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.1651 - accuracy: 0.9517\n",
            "Epoch 781/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.1175 - accuracy: 0.9678\n",
            "Epoch 782/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0285 - accuracy: 0.9927\n",
            "Epoch 783/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0336 - accuracy: 0.9886\n",
            "Epoch 784/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0236 - accuracy: 0.9938\n",
            "Epoch 785/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0329 - accuracy: 0.9912\n",
            "Epoch 786/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0202 - accuracy: 0.9948\n",
            "Epoch 787/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0184 - accuracy: 0.9933\n",
            "Epoch 788/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0166 - accuracy: 0.9938\n",
            "Epoch 789/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0171 - accuracy: 0.9953\n",
            "Epoch 790/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0182 - accuracy: 0.9948\n",
            "Epoch 791/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0203 - accuracy: 0.9953\n",
            "Epoch 792/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0219 - accuracy: 0.9938\n",
            "Epoch 793/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0263 - accuracy: 0.9938\n",
            "Epoch 794/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0265 - accuracy: 0.9943\n",
            "Epoch 795/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0208 - accuracy: 0.9953\n",
            "Epoch 796/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0212 - accuracy: 0.9933\n",
            "Epoch 797/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0249 - accuracy: 0.9922\n",
            "Epoch 798/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0268 - accuracy: 0.9917\n",
            "Epoch 799/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0268 - accuracy: 0.9948\n",
            "Epoch 800/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0203 - accuracy: 0.9938\n",
            "Epoch 801/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0307 - accuracy: 0.9922\n",
            "Epoch 802/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0278 - accuracy: 0.9922\n",
            "Epoch 803/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0204 - accuracy: 0.9938\n",
            "Epoch 804/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0246 - accuracy: 0.9938\n",
            "Epoch 805/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0225 - accuracy: 0.9927\n",
            "Epoch 806/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0249 - accuracy: 0.9927\n",
            "Epoch 807/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0163 - accuracy: 0.9938\n",
            "Epoch 808/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0212 - accuracy: 0.9948\n",
            "Epoch 809/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0198 - accuracy: 0.9953\n",
            "Epoch 810/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0252 - accuracy: 0.9943\n",
            "Epoch 811/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0207 - accuracy: 0.9953\n",
            "Epoch 812/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0163 - accuracy: 0.9958\n",
            "Epoch 813/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0254 - accuracy: 0.9938\n",
            "Epoch 814/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0226 - accuracy: 0.9943\n",
            "Epoch 815/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0223 - accuracy: 0.9927\n",
            "Epoch 816/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0202 - accuracy: 0.9948\n",
            "Epoch 817/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0210 - accuracy: 0.9922\n",
            "Epoch 818/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0315 - accuracy: 0.9922\n",
            "Epoch 819/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0282 - accuracy: 0.9922\n",
            "Epoch 820/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0191 - accuracy: 0.9943\n",
            "Epoch 821/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0215 - accuracy: 0.9938\n",
            "Epoch 822/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0509 - accuracy: 0.9834\n",
            "Epoch 823/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0269 - accuracy: 0.9933\n",
            "Epoch 824/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0262 - accuracy: 0.9917\n",
            "Epoch 825/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0177 - accuracy: 0.9943\n",
            "Epoch 826/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0195 - accuracy: 0.9948\n",
            "Epoch 827/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0189 - accuracy: 0.9933\n",
            "Epoch 828/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0225 - accuracy: 0.9948\n",
            "Epoch 829/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0204 - accuracy: 0.9948\n",
            "Epoch 830/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0210 - accuracy: 0.9943\n",
            "Epoch 831/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0232 - accuracy: 0.9933\n",
            "Epoch 832/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0260 - accuracy: 0.9933\n",
            "Epoch 833/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0798 - accuracy: 0.9735\n",
            "Epoch 834/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.1255 - accuracy: 0.9668\n",
            "Epoch 835/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0566 - accuracy: 0.9813\n",
            "Epoch 836/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0374 - accuracy: 0.9891\n",
            "Epoch 837/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0434 - accuracy: 0.9860\n",
            "Epoch 838/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0296 - accuracy: 0.9891\n",
            "Epoch 839/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0171 - accuracy: 0.9933\n",
            "Epoch 840/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0253 - accuracy: 0.9922\n",
            "Epoch 841/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0217 - accuracy: 0.9927\n",
            "Epoch 842/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0185 - accuracy: 0.9933\n",
            "Epoch 843/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0220 - accuracy: 0.9922\n",
            "Epoch 844/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0207 - accuracy: 0.9907\n",
            "Epoch 845/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0199 - accuracy: 0.9922\n",
            "Epoch 846/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0215 - accuracy: 0.9933\n",
            "Epoch 847/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0199 - accuracy: 0.9927\n",
            "Epoch 848/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0163 - accuracy: 0.9953\n",
            "Epoch 849/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0191 - accuracy: 0.9948\n",
            "Epoch 850/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0190 - accuracy: 0.9927\n",
            "Epoch 851/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0223 - accuracy: 0.9927\n",
            "Epoch 852/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0173 - accuracy: 0.9948\n",
            "Epoch 853/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0172 - accuracy: 0.9943\n",
            "Epoch 854/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0205 - accuracy: 0.9933\n",
            "Epoch 855/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0191 - accuracy: 0.9948\n",
            "Epoch 856/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0283 - accuracy: 0.9943\n",
            "Epoch 857/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0243 - accuracy: 0.9922\n",
            "Epoch 858/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 0.9933\n",
            "Epoch 859/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0183 - accuracy: 0.9953\n",
            "Epoch 860/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0194 - accuracy: 0.9943\n",
            "Epoch 861/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0231 - accuracy: 0.9938\n",
            "Epoch 862/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0187 - accuracy: 0.9943\n",
            "Epoch 863/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0225 - accuracy: 0.9933\n",
            "Epoch 864/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0218 - accuracy: 0.9927\n",
            "Epoch 865/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0177 - accuracy: 0.9948\n",
            "Epoch 866/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0166 - accuracy: 0.9948\n",
            "Epoch 867/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0181 - accuracy: 0.9943\n",
            "Epoch 868/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0191 - accuracy: 0.9948\n",
            "Epoch 869/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0298 - accuracy: 0.9912\n",
            "Epoch 870/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0320 - accuracy: 0.9907\n",
            "Epoch 871/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0523 - accuracy: 0.9860\n",
            "Epoch 872/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9792\n",
            "Epoch 873/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0344 - accuracy: 0.9886\n",
            "Epoch 874/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0312 - accuracy: 0.9907\n",
            "Epoch 875/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0512 - accuracy: 0.9860\n",
            "Epoch 876/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0472 - accuracy: 0.9829\n",
            "Epoch 877/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.1275 - accuracy: 0.9699\n",
            "Epoch 878/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0581 - accuracy: 0.9792\n",
            "Epoch 879/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0254 - accuracy: 0.9907\n",
            "Epoch 880/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0217 - accuracy: 0.9922\n",
            "Epoch 881/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0193 - accuracy: 0.9927\n",
            "Epoch 882/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0168 - accuracy: 0.9948\n",
            "Epoch 883/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0204 - accuracy: 0.9958\n",
            "Epoch 884/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0175 - accuracy: 0.9948\n",
            "Epoch 885/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0189 - accuracy: 0.9938\n",
            "Epoch 886/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0203 - accuracy: 0.9927\n",
            "Epoch 887/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 0.9953\n",
            "Epoch 888/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0218 - accuracy: 0.9943\n",
            "Epoch 889/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0184 - accuracy: 0.9933\n",
            "Epoch 890/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0203 - accuracy: 0.9953\n",
            "Epoch 891/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0182 - accuracy: 0.9943\n",
            "Epoch 892/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0197 - accuracy: 0.9933\n",
            "Epoch 893/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0160 - accuracy: 0.9953\n",
            "Epoch 894/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0178 - accuracy: 0.9938\n",
            "Epoch 895/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0209 - accuracy: 0.9943\n",
            "Epoch 896/1000\n",
            "61/61 [==============================] - 0s 5ms/step - loss: 0.0249 - accuracy: 0.9933\n",
            "Epoch 897/1000\n",
            "61/61 [==============================] - 0s 5ms/step - loss: 0.0219 - accuracy: 0.9938\n",
            "Epoch 898/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0305 - accuracy: 0.9912\n",
            "Epoch 899/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0205 - accuracy: 0.9948\n",
            "Epoch 900/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0382 - accuracy: 0.9907\n",
            "Epoch 901/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0243 - accuracy: 0.9922\n",
            "Epoch 902/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0250 - accuracy: 0.9938\n",
            "Epoch 903/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0210 - accuracy: 0.9938\n",
            "Epoch 904/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0206 - accuracy: 0.9938\n",
            "Epoch 905/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0483 - accuracy: 0.9855\n",
            "Epoch 906/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0400 - accuracy: 0.9855\n",
            "Epoch 907/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0656 - accuracy: 0.9777\n",
            "Epoch 908/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0557 - accuracy: 0.9829\n",
            "Epoch 909/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0613 - accuracy: 0.9839\n",
            "Epoch 910/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0414 - accuracy: 0.9875\n",
            "Epoch 911/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0220 - accuracy: 0.9943\n",
            "Epoch 912/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0162 - accuracy: 0.9958\n",
            "Epoch 913/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0168 - accuracy: 0.9958\n",
            "Epoch 914/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0172 - accuracy: 0.9938\n",
            "Epoch 915/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0170 - accuracy: 0.9948\n",
            "Epoch 916/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0195 - accuracy: 0.9938\n",
            "Epoch 917/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 0.9943\n",
            "Epoch 918/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 0.9948\n",
            "Epoch 919/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0165 - accuracy: 0.9943\n",
            "Epoch 920/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 0.9948\n",
            "Epoch 921/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0183 - accuracy: 0.9948\n",
            "Epoch 922/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0163 - accuracy: 0.9953\n",
            "Epoch 923/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0162 - accuracy: 0.9958\n",
            "Epoch 924/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0168 - accuracy: 0.9927\n",
            "Epoch 925/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0238 - accuracy: 0.9933\n",
            "Epoch 926/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0176 - accuracy: 0.9943\n",
            "Epoch 927/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0167 - accuracy: 0.9953\n",
            "Epoch 928/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0171 - accuracy: 0.9948\n",
            "Epoch 929/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0175 - accuracy: 0.9948\n",
            "Epoch 930/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0222 - accuracy: 0.9933\n",
            "Epoch 931/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0268 - accuracy: 0.9927\n",
            "Epoch 932/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0190 - accuracy: 0.9938\n",
            "Epoch 933/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0275 - accuracy: 0.9933\n",
            "Epoch 934/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0211 - accuracy: 0.9943\n",
            "Epoch 935/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0191 - accuracy: 0.9938\n",
            "Epoch 936/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0510 - accuracy: 0.9824\n",
            "Epoch 937/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0829 - accuracy: 0.9756\n",
            "Epoch 938/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.1731 - accuracy: 0.9554\n",
            "Epoch 939/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0446 - accuracy: 0.9844\n",
            "Epoch 940/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0254 - accuracy: 0.9922\n",
            "Epoch 941/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0177 - accuracy: 0.9943\n",
            "Epoch 942/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0155 - accuracy: 0.9953\n",
            "Epoch 943/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0187 - accuracy: 0.9953\n",
            "Epoch 944/1000\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 0.0171 - accuracy: 0.9948\n",
            "Epoch 945/1000\n",
            "61/61 [==============================] - 0s 6ms/step - loss: 0.0204 - accuracy: 0.9943\n",
            "Epoch 946/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0205 - accuracy: 0.9938\n",
            "Epoch 947/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9943\n",
            "Epoch 948/1000\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0176 - accuracy: 0.9953\n",
            "Epoch 949/1000\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 0.0230 - accuracy: 0.9938\n",
            "Epoch 950/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0209 - accuracy: 0.9948\n",
            "Epoch 951/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0176 - accuracy: 0.9933\n",
            "Epoch 952/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0185 - accuracy: 0.9938\n",
            "Epoch 953/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0162 - accuracy: 0.9948\n",
            "Epoch 954/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0193 - accuracy: 0.9943\n",
            "Epoch 955/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0283 - accuracy: 0.9938\n",
            "Epoch 956/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0190 - accuracy: 0.9943\n",
            "Epoch 957/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0203 - accuracy: 0.9938\n",
            "Epoch 958/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0262 - accuracy: 0.9938\n",
            "Epoch 959/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0206 - accuracy: 0.9948\n",
            "Epoch 960/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0163 - accuracy: 0.9948\n",
            "Epoch 961/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0199 - accuracy: 0.9943\n",
            "Epoch 962/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0190 - accuracy: 0.9953\n",
            "Epoch 963/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0255 - accuracy: 0.9933\n",
            "Epoch 964/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0199 - accuracy: 0.9938\n",
            "Epoch 965/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0215 - accuracy: 0.9927\n",
            "Epoch 966/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0215 - accuracy: 0.9938\n",
            "Epoch 967/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0185 - accuracy: 0.9953\n",
            "Epoch 968/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0278 - accuracy: 0.9917\n",
            "Epoch 969/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0217 - accuracy: 0.9933\n",
            "Epoch 970/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 0.9922\n",
            "Epoch 971/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0198 - accuracy: 0.9933\n",
            "Epoch 972/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0196 - accuracy: 0.9943\n",
            "Epoch 973/1000\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.0178 - accuracy: 0.9948\n",
            "Epoch 974/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0225 - accuracy: 0.9933\n",
            "Epoch 975/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0240 - accuracy: 0.9938\n",
            "Epoch 976/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0311 - accuracy: 0.9933\n",
            "Epoch 977/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0179 - accuracy: 0.9943\n",
            "Epoch 978/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0277 - accuracy: 0.9917\n",
            "Epoch 979/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0763 - accuracy: 0.9798\n",
            "Epoch 980/1000\n",
            "61/61 [==============================] - 0s 5ms/step - loss: 0.1057 - accuracy: 0.9663\n",
            "Epoch 981/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0782 - accuracy: 0.9761\n",
            "Epoch 982/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0827 - accuracy: 0.9787\n",
            "Epoch 983/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0469 - accuracy: 0.9870\n",
            "Epoch 984/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0321 - accuracy: 0.9917\n",
            "Epoch 985/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0234 - accuracy: 0.9917\n",
            "Epoch 986/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0228 - accuracy: 0.9927\n",
            "Epoch 987/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0201 - accuracy: 0.9943\n",
            "Epoch 988/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0169 - accuracy: 0.9948\n",
            "Epoch 989/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0153 - accuracy: 0.9948\n",
            "Epoch 990/1000\n",
            "61/61 [==============================] - 0s 5ms/step - loss: 0.0165 - accuracy: 0.9948\n",
            "Epoch 991/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 0.9958\n",
            "Epoch 992/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0151 - accuracy: 0.9948\n",
            "Epoch 993/1000\n",
            "61/61 [==============================] - 0s 5ms/step - loss: 0.0150 - accuracy: 0.9953\n",
            "Epoch 994/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0140 - accuracy: 0.9958\n",
            "Epoch 995/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0176 - accuracy: 0.9953\n",
            "Epoch 996/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0176 - accuracy: 0.9948\n",
            "Epoch 997/1000\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0193 - accuracy: 0.9927\n",
            "Epoch 998/1000\n",
            "61/61 [==============================] - 0s 5ms/step - loss: 0.0186 - accuracy: 0.9948\n",
            "Epoch 999/1000\n",
            "61/61 [==============================] - 0s 5ms/step - loss: 0.0179 - accuracy: 0.9953\n",
            "Epoch 1000/1000\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0176 - accuracy: 0.9948\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model using test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_train_scaled, y_train_encoded,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "id": "RN58VN5qIK7k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0722de47-3b07-4f86-c84e-173e7629c1db"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "61/61 - 0s - loss: 0.0123 - accuracy: 0.9964 - 252ms/epoch - 4ms/step\n",
            "Loss: 0.012295887805521488, Accuracy: 0.9963673949241638\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_array = y_test.to_numpy()\n",
        "y_test_encoded = encoder.transform(y_test_array.reshape(-1,1))\n",
        "\n",
        "# Evaluate model using test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test_encoded,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "id": "QHZpOJvAWaUq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d2401f7-fe1a-40c5-91e4-15b3a9a55c5f"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "241/241 - 0s - loss: 5.1983 - accuracy: 0.6236 - 320ms/epoch - 1ms/step\n",
            "Loss: 5.19827127456665, Accuracy: 0.6235736608505249\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make predictions using the testing data\n",
        "\n",
        "nn_predictions = nn.predict(X_test_scaled)\n",
        "# c_matrix = confusion_matrix(y_test_encoded, nn_predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mt9vKypL04w3",
        "outputId": "c42ed841-0cdd-4362-886d-62a544e997e1"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "241/241 [==============================] - 1s 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCRgI0Ube3iV"
      },
      "source": [
        "# Keras Tuner Model Optimization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare Next Iteration of Model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "pgt9Ie9zIWyb"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "fBPUcPn1dgVb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b330fb89-66cb-4bea-bf03-0f96c944d9e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# One-hot encode the target variable y_train\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "\n",
        "# Convert DataFrame to numpy array before reshaping\n",
        "y_array = y.to_numpy()\n",
        "\n",
        "# One-hot encode the target variable y_train\n",
        "y_encoded = encoder.fit_transform(y_array.reshape(-1, 1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "w4NNWU6Ir1rU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "f2980f6c-7098-46a9-dce2-143536f85da9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   N_Days    Age  Bilirubin  Cholesterol  Albumin  Copper  Alk_Phos    SGOT  \\\n",
              "0    2221  18499        0.5        149.0     4.04   227.0     598.0   52.70   \n",
              "1    1230  19724        0.5        219.0     3.93    22.0     663.0   45.00   \n",
              "2    4184  11839        0.5        320.0     3.54    51.0    1243.0  122.45   \n",
              "3    2090  16467        0.7        255.0     3.74    23.0    1024.0   77.50   \n",
              "4    2105  21699        1.9        486.0     3.54    74.0    1052.0  108.50   \n",
              "\n",
              "   Tryglicerides  Platelets  ...  Sex_M  Ascites_N  Ascites_Y  Hepatomegaly_N  \\\n",
              "0           57.0      256.0  ...    0.0        1.0        0.0             0.0   \n",
              "1           75.0      220.0  ...    1.0        0.0        1.0             1.0   \n",
              "2           80.0      225.0  ...    0.0        1.0        0.0             1.0   \n",
              "3           58.0      151.0  ...    0.0        1.0        0.0             1.0   \n",
              "4          109.0      151.0  ...    0.0        1.0        0.0             0.0   \n",
              "\n",
              "   Hepatomegaly_Y  Spiders_N  Spiders_Y  Edema_N  Edema_S  Edema_Y  \n",
              "0             1.0        1.0        0.0      1.0      0.0      0.0  \n",
              "1             0.0        0.0        1.0      1.0      0.0      0.0  \n",
              "2             0.0        1.0        0.0      1.0      0.0      0.0  \n",
              "3             0.0        1.0        0.0      1.0      0.0      0.0  \n",
              "4             1.0        1.0        0.0      1.0      0.0      0.0  \n",
              "\n",
              "[5 rows x 27 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-59293481-d8b6-4cb8-9a22-156fd30d30a6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>N_Days</th>\n",
              "      <th>Age</th>\n",
              "      <th>Bilirubin</th>\n",
              "      <th>Cholesterol</th>\n",
              "      <th>Albumin</th>\n",
              "      <th>Copper</th>\n",
              "      <th>Alk_Phos</th>\n",
              "      <th>SGOT</th>\n",
              "      <th>Tryglicerides</th>\n",
              "      <th>Platelets</th>\n",
              "      <th>...</th>\n",
              "      <th>Sex_M</th>\n",
              "      <th>Ascites_N</th>\n",
              "      <th>Ascites_Y</th>\n",
              "      <th>Hepatomegaly_N</th>\n",
              "      <th>Hepatomegaly_Y</th>\n",
              "      <th>Spiders_N</th>\n",
              "      <th>Spiders_Y</th>\n",
              "      <th>Edema_N</th>\n",
              "      <th>Edema_S</th>\n",
              "      <th>Edema_Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2221</td>\n",
              "      <td>18499</td>\n",
              "      <td>0.5</td>\n",
              "      <td>149.0</td>\n",
              "      <td>4.04</td>\n",
              "      <td>227.0</td>\n",
              "      <td>598.0</td>\n",
              "      <td>52.70</td>\n",
              "      <td>57.0</td>\n",
              "      <td>256.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1230</td>\n",
              "      <td>19724</td>\n",
              "      <td>0.5</td>\n",
              "      <td>219.0</td>\n",
              "      <td>3.93</td>\n",
              "      <td>22.0</td>\n",
              "      <td>663.0</td>\n",
              "      <td>45.00</td>\n",
              "      <td>75.0</td>\n",
              "      <td>220.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4184</td>\n",
              "      <td>11839</td>\n",
              "      <td>0.5</td>\n",
              "      <td>320.0</td>\n",
              "      <td>3.54</td>\n",
              "      <td>51.0</td>\n",
              "      <td>1243.0</td>\n",
              "      <td>122.45</td>\n",
              "      <td>80.0</td>\n",
              "      <td>225.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2090</td>\n",
              "      <td>16467</td>\n",
              "      <td>0.7</td>\n",
              "      <td>255.0</td>\n",
              "      <td>3.74</td>\n",
              "      <td>23.0</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>77.50</td>\n",
              "      <td>58.0</td>\n",
              "      <td>151.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2105</td>\n",
              "      <td>21699</td>\n",
              "      <td>1.9</td>\n",
              "      <td>486.0</td>\n",
              "      <td>3.54</td>\n",
              "      <td>74.0</td>\n",
              "      <td>1052.0</td>\n",
              "      <td>108.50</td>\n",
              "      <td>109.0</td>\n",
              "      <td>151.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 27 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-59293481-d8b6-4cb8-9a22-156fd30d30a6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-59293481-d8b6-4cb8-9a22-156fd30d30a6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-59293481-d8b6-4cb8-9a22-156fd30d30a6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6734d76a-53a8-4180-ad8f-00f05c5f0102\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6734d76a-53a8-4180-ad8f-00f05c5f0102')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6734d76a-53a8-4180-ad8f-00f05c5f0102 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X"
            }
          },
          "metadata": {},
          "execution_count": 120
        }
      ],
      "source": [
        "# Encode the remaining categorical variables (Status, Drug) using get_dummies\n",
        "X = pd.get_dummies(X, dtype=int)\n",
        "\n",
        "#preview dataset with categorical data converted\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfJh793yDRRV"
      },
      "outputs": [],
      "source": [
        "# Use sklearn to split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, random_state=78)\n",
        "\n",
        "# Create scaler instance\n",
        "X_scaler = skl.preprocessing.StandardScaler()\n",
        "\n",
        "# Fit the scaler\n",
        "X_scaler.fit(X_train_scaled)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)\n",
        "print(X_train_scaled)\n",
        "print(X_test_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqhKqTPX6LTY"
      },
      "outputs": [],
      "source": [
        "# Define the function to create the model\n",
        "def create_model(hp):\n",
        "    nn_model = tf.keras.models.Sequential()\n",
        "\n",
        "    # Allow KerasTuner to decide which activation function to use in hidden layers\n",
        "    activation = hp.Choice('activation', ['relu', 'tanh', 'sigmoid'])\n",
        "\n",
        "    # Allow KerasTuner to decide the number of neurons in the first layer\n",
        "    nn_model.add(tf.keras.layers.Dense(units=hp.Int('first_units',\n",
        "      min_value=1,\n",
        "      max_value=50,\n",
        "      step=5),\n",
        "      activation=activation,\n",
        "      input_dim=27))\n",
        "\n",
        "    # Allow KerasTuner to decide the number of hidden layers and neurons in hidden layers\n",
        "    for i in range(hp.Int('num_layers', 1, 5)):\n",
        "      nn_model.add(tf.keras.layers.Dense(units=hp.Int('units_' + str(i),\n",
        "      min_value=1,\n",
        "      max_value=50,\n",
        "      step=5),\n",
        "      activation=activation))\n",
        "    nn_model.add(tf.keras.layers.Dense(units=3, activation=\"softmax\"))\n",
        "    nn_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
        "    return nn_model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYf9EW82gEF2"
      },
      "outputs": [],
      "source": [
        "# Create the tuner\n",
        "tuner = kt.Hyperband(create_model,\n",
        "objective='val_accuracy',\n",
        "max_epochs=100,\n",
        "hyperband_iterations=2,\n",
        "overwrite = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IACaRfN-HbDI"
      },
      "outputs": [],
      "source": [
        "# Search for the best hyperparameters\n",
        "tuner.search(X_train_scaled, y_train, epochs=1000, validation_data=(X_test_scaled, y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model using test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_train_scaled, y_train_encoded,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "id": "6A9M4FO_IUS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PCA Optimization"
      ],
      "metadata": {
        "id": "MNOajEzGhzhm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Q_De2IMBESqy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the PCA model and other dependencies\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n"
      ],
      "metadata": {
        "id": "npBMFmfghxiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preview the df\n",
        "liver_clean_df"
      ],
      "metadata": {
        "id": "UdsHmL4SoUGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check columns\n",
        "# We want to take out the 'Stage' column for the PCA since it is the target/dependent variable. This will leave us with everything else, which are the feature/independent variables\n",
        "liver_clean_df.columns"
      ],
      "metadata": {
        "id": "eTWkpqORHpis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the 'Stage' column. PCA only needs the independent variables\n",
        "liver_clean_df_preprocess = liver_clean_df.drop(columns=['Stage'])\n",
        "\n",
        "# Recheck columns to make sure 'Stage' dropped\n",
        "liver_clean_df_preprocess.columns"
      ],
      "metadata": {
        "id": "hWy9x0_0IUm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale the data\n",
        "liver_clean_std_df = StandardScaler().fit_transform(liver_clean_df_preprocess)\n",
        "liver_clean_std_df"
      ],
      "metadata": {
        "id": "boN1x5uxLRcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a PCA model instance with n_components = 3\n",
        "pca = PCA(n_components = 3)"
      ],
      "metadata": {
        "id": "PPu2RcvQhxfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the PCA model on the liver_clean_df\n",
        "liver_clean_pca = pca.fit_transform(liver_clean_std_df)\n",
        "\n",
        "# View first 5 rows of the list data\n",
        "liver_clean_pca[:5]"
      ],
      "metadata": {
        "id": "AsyentCvhxc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the explained variance and total explained variance\n",
        "explained_var = pca.explained_variance_ratio_\n",
        "\n",
        "total_explained_var = np.cumsum(explained_var)\n",
        "print(f\"Explained Variance: {explained_var}\")\n",
        "print(f\"Total Explained Variance: {total_explained_var}\")"
      ],
      "metadata": {
        "id": "2qwWgIDOhxZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the PCA df\n",
        "liver_pca_df = pd.DataFrame(\n",
        "    liver_clean_pca,\n",
        "    columns=[\"PCA1\", \"PCA2\", \"PCA3\"]\n",
        ")\n",
        "\n",
        "# Preview the df\n",
        "liver_pca_df.head()"
      ],
      "metadata": {
        "id": "AInOzh0ehxWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PCA Dataframe into elbow method"
      ],
      "metadata": {
        "id": "MEtIKfSStNVF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Suppress the warning\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "# Create list to store inertia values and values of k\n",
        "inertia = []\n",
        "k = list(range(1, 11))\n",
        "\n",
        "# Append the value of computer inertia from 'inertia_' attribute of the KMeans model instance\n",
        "for i in k:\n",
        "    km = KMeans(n_clusters=i, random_state=0)\n",
        "    km.fit(liver_pca_df)\n",
        "    inertia.append(km.inertia_)\n",
        "\n",
        "# Define a df to hold the values for k and the corresponding inertia\n",
        "elbow_data = {\"k\": k, \"inertia\": inertia}\n",
        "elbow_df = pd.DataFrame(elbow_data)\n",
        "\n",
        "elbow_df.head(10)\n"
      ],
      "metadata": {
        "id": "rD6lEE22hxPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the elbow curve using pyplot\n",
        "plt.plot(elbow_df['k'], elbow_df[\"inertia\"])\n",
        "plt.xlabel(\"Number of Clusters: k\")\n",
        "plt.ylabel(\"Inertia\")\n",
        "plt.title(\"PCA Elbow Curve\")\n",
        "plt.show()\n",
        "\n",
        "print(f\"The elbow curve shows that the best k-value is 4.\")"
      ],
      "metadata": {
        "id": "qXCswlxEhw8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K-means with PCA Data\n",
        "\n",
        "### 1. Try with k = 4."
      ],
      "metadata": {
        "id": "NMFgtRwf1beM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the K-means model with k=4 (based on the plot above)\n",
        "model = KMeans(n_clusters=4, random_state=0)\n",
        "\n",
        "# Fit the model to the PCA\n",
        "model.fit(liver_pca_df)\n"
      ],
      "metadata": {
        "id": "qN34616451Jg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the clusters\n",
        "predictions = model.predict(liver_pca_df)\n",
        "\n",
        "# Print the predictions\n",
        "print(predictions)"
      ],
      "metadata": {
        "id": "O0vXO4AB21dU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create copy of PCA df\n",
        "pca_df_predictions = liver_pca_df.copy()\n",
        "\n",
        "# Add a column to the new df with the predicted clusters\n",
        "pca_df_predictions['pca_clusters'] = predictions\n",
        "\n",
        "# Preview the df\n",
        "pca_df_predictions.head()"
      ],
      "metadata": {
        "id": "Xkor5JFo3A7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatter plot of the predicted clusters\n",
        "plt.scatter(pca_df_predictions['PCA1'], pca_df_predictions['PCA2'], c=pca_df_predictions['pca_clusters'])\n",
        "plt.xlabel('PCA1')\n",
        "plt.ylabel('PCA2')\n",
        "plt.title('PCA Clusters')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tBG3Zxi032LN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Try with k = 3"
      ],
      "metadata": {
        "id": "7B72B56nPOnt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the K-means model with k=3\n",
        "model = KMeans(n_clusters=3, random_state=0)\n",
        "\n",
        "# Fit the model to the PCA\n",
        "model.fit(liver_pca_df)"
      ],
      "metadata": {
        "id": "BZ49Q9zkPNxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the clusters\n",
        "predictions = model.predict(liver_pca_df)\n",
        "\n",
        "# Print the predictions\n",
        "print(predictions)"
      ],
      "metadata": {
        "id": "9nVX6rjpPaOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create copy of PCA df\n",
        "pca_df_predictions = liver_pca_df.copy()\n",
        "\n",
        "# Add a column to the new df with the predicted clusters\n",
        "pca_df_predictions['pca_clusters'] = predictions\n",
        "\n",
        "# Preview the df\n",
        "pca_df_predictions.head()"
      ],
      "metadata": {
        "id": "khNIWlR2PoKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatter plot of the predicted clusters\n",
        "plt.scatter(pca_df_predictions['PCA1'], pca_df_predictions['PCA2'], c=pca_df_predictions['pca_clusters'])\n",
        "plt.xlabel('PCA1')\n",
        "plt.ylabel('PCA2')\n",
        "plt.title('PCA Clusters')\n",
        "plt.legend('pca_clusters')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_QfeQKyIPs9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using k = 3 seems to make the most sense in this case, especially with knowing that there are only 3 target outputs (i.e. Stages 1, 2, or 3). Using 4 clusters caused some overlap in the clusters, whereas using 3 clusters gave more distinct groupings.\n",
        "\n",
        "Overall, using PCA for this dataset was not a good fit. The low variance that was calculated, where the highest was 0.38%, did not indicate that a lot of the original data was maintained and likely would not have had the same impact."
      ],
      "metadata": {
        "id": "CNMLU7J8CoH4"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}